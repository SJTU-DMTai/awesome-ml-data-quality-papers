# Awesome ML Data Quality Papers

This is a list of papers about training data quality management for ML models.

## Introduction

Data scientists spend ∼80% time on data preparation for an ML pipeline since the data quality issues are unknown beforehand thereby leading to iterative debugging [1]. A good Data Quality Management System for ML (**DQMS for ML**) helps data scientists break free from the arduous process of data selection and debugging, particularly in the current era of big data and large models. Automating the management of training data quality effectively is crucial for improving the efficiency and quality of ML pipelines.

With the emergence and development of "**Data-Centric AI**", there has been increasing research focus on optimizing the quality of training data rather than solely concentrating on model structures and training strategies. This is the motivation behind maintaining this repository.

Before we proceed, let's define **data quality for ML**. In contrast to traditional data cleaning, training data quality for ML refers to the impact of individual or groups of data samples on the behavior of ML models for a given task. It's important to note that the behavior of the model we are concerned with goes beyond performance metrics like accuracy, recall, AUC, MSE, etc. We also consider more generalizable metrics such as model fairness, robustness, and so on.

Considering the following pipeline, DQMS acts as a **middleware** between data, ML model, and user, necessitating interactions with each of them.

<div align=center>
<img src="./framework.png" width = "80%" />
</div>


A DQMS for ML typically consists of three components: **Data Sculptor** [2], **Data Attributer**, and **Data Profiler**. To achieve a well-performing ML model, multiple rounds of training are often required. In this process, the DQMS needs to iteratively adjust the training data based on the results of each round of model training. The workflow of DQMS in one round of training is as follows: (a) Data sculptor first acquires the training dataset from a data source and trains the ML model with it. (b) After training for one round (several epochs), Data Attributer absorbs feedback from the model and user's task requirements and computes the data quality assessment. (c) Data Profiler then provides a user-friendly summary of the training data. (d) Meanwhile, Data Sculptor utilizes the data quality assessment as feedback to construct higher-quality training data, thus initiating a new iteration.

We collect the recent papers about DQMS for ML and annotate the relevant DQMS components involved in these papers, where `DS` = Data Sculptor, `DA` = Data Attributer, and `DP` = Data Profiler. First, we will introduce some papers and researchers that we consider influential, to help starters quickly gain an overall understanding of DQMS for ML. Then, we will present a complete list of relevant papers, which is sorted by publication date.

## Selected Influential Works

| Venue                | Paper                                                        |                            Links                             |   Tags    |
| :------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: |
| ICML'17              | Understanding Black-box Predictions via Influence Functions  | [paper](https://arxiv.org/pdf/1703.04730.pdf) [code](https://github.com/kohpangwei/influence-release) |   `DA`    |
| ICML'19              | Data Shapley: Equitable Valuation of Data for Machine Learning | [paper](https://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf) [code](https://github.com/amiratag/DataShapley) |   `DA`    |
| VLDB'19              | Efficient task-specific data valuation for nearest neighbor algorithms |     [paper](https://vldb.org/pvldb/vol12/p1610-jia.pdf)      |   `DA`    |
| SIGMOD'20            | Complaint Driven Training Data Debugging for Query'2.0       | [paper](https://arxiv.org/pdf/2004.05722.pdf) [video](https://www.youtube.com/watch?v=qvgBmM1LP38) |   `DA`    |
| ICML'20              | Data Valuation using Reinforcement Learning                  | [paper](https://proceedings.mlr.press/v119/yoon20a/yoon20a.pdf) [code](https://github.com/google-research/google-research/tree/master/dvrl) |   `DA`    |
| NeurIPS'20           | Estimating Training Data Influence by Tracing Gradient Descent | [paper](https://papers.NeurIPS.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf) [code](https://github.com/frederick0329/TracIn) |   `DA`    |
| SIGMOD'22            | Interpretable Data-Based Explanations for Fairness Debugging | [paper](https://arxiv.org/pdf/2112.09745.pdf) [video](https://www.youtube.com/watch?v=bt_VL1eSu30) | `DA` `DP` |
| ICML'22              | Datamodels: Predicting Predictions from Training Data        | [paper](https://proceedings.mlr.press/v162/ilyas22a/ilyas22a.pdf) [code](https://github.com/MadryLab/datamodels-data) |   `DA`    |
| ICML'22              | Meaningfully Debugging Model Mistakes using Conceptual Counterfactual Explanations | [papeer](https://proceedings.mlr.press/v162/abid22a/abid22a.pdf) [code](https://github.com/mertyg/debug-mistakes-cce) | `DS` `DP` |
| SIGMOD'23            | GoodCore: Coreset Selection over Incomplete Data for Data-effective and Data-efficient Machine Learning |     [paper](https://dl.acm.org/doi/pdf/10.1145/3589302)      |   `DS`    |
| ICML'23              | TRAK: Attributing Model Behavior at Scale                    | [paper](https://openreview.net/pdf?id=PBRArApxMh) [code](https://github.com/MadryLab/trak) |   `DA`    |
| ICML'23              | Discover and Cure: Concept-aware Mitigation of Spurious Correlation | [paper](https://openreview.net/pdf?id=QDxtrlPmfB) [code](https://github.com/Wuyxin/DISC) | `DS` `DA` |
| NeurIPS'23           | Data Selection for Language Models via Importance Resampling | [paper](https://openreview.net/pdf?id=uPSQv0leAu) [code](https://github.com/p-lambda/dsir) |   `DS`    |
| ICLR'24              | InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning | [paper](https://openreview.net/pdf?id=C61sk5LsK6) [code](https://github.com/NUS-HPC-AI-Lab/InfoBatch) |   `DS`    |
| ICLR'24              | "What Data Benefits My Classifier?" Enhancing Model Performance and Interpretability through Influence-Based Data Selection | [paper](https://openreview.net/pdf?id=HE9eUQlAvo) [code](https://github.com/anshuman23/InfDataSel) | `DS` `DA` |
| ICLR'24              | Canonpipe: Data Debugging with Shapley Importance over Machine Learning Pipelines | [paper](https://openreview.net/pdf?id=qxGXjWxabq) [code](https://github.com/easeml/datascope) |   `DA`    |
| VLDB'24              | Counterfactual Explanation of Shapley Value in Data Coalitions | [paper](https://www.vldb.org/pvldb/vol17/p3332-si.pdf) [code](https://github.com/michelleeesi/shapley_counterfactual) |   `DA`    |
| VLDB'24              | A Comprehensive Study of Shapley Value in Data Analytics     |          [paper](https://arxiv.org/pdf/2412.01460)           |   `DA`    |
| ICML'24              | LESS: Selecting Influential Data for Targeted Instruction Tuning | [paper](https://arxiv.org/pdf/2402.04333v1) [code](https://github.com/princeton-nlp/LESS) |   `DS`    |
| ICML'24              | Rethinking Data Shapley for Data Selection Tasks: Misleads and Merits |          [paper](https://arxiv.org/pdf/2405.03875)           | `DA` `DS` |
| NeurIPS'24           | Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution | [paper](https://openreview.net/pdf?id=ZdWTN2HOie) [code](https://github.com/chanwkimlab/amortized-attribution) [code](https://github.com/chanwkimlab/amortized-attribution) |   `DA`    |
| ICLR'25              | Data Shapley in One Training Run                             |      [paper](https://openreview.net/pdf?id=HD6bWcj87Y)       |   `DA`    |
|                      |                                                              |                                                              |           |
| NeurIPS'23 Benchmark | OpenDataVal: a Unified Benchmark for Data Valuation          | [paper](https://openreview.net/pdf?id=eEK99egXeB) [code](https://opendataval.github.io/) |   `DA`    |
| NeurIPS'23 Tutorial  | Data Contribution Estimation for Machine Learning            |    [Website](https://icml.cc/virtual/2024/tutorial/35228)    |   `DA`    |
| Machine Learning'24  | Training Data Influence Analysis and Estimation: A Survey    | [paper](https://arxiv.org/pdf/2212.04612.pdf) [code](https://github.com/ZaydH/influence_analysis_papers) |   `DA`    |
| NeurIPS'24 Tutorial  | Advancing Data Selection for Foundation Models: From Heuristics to Principled Methods |  [Webseite](https://neurips.cc/virtual/2024/tutorial/99530)  |   `DS`    |
|                      | A Survey of Data Attribution: Methods, Applications, and Evaluation in the Era of Generative AI |     [paper](https://hal.science/hal-05230469v1/document)     |   `DA`    |

## Researchers

[Ruoxi Jia](https://scholar.google.com/citations?user=JCrug-YAAAAJ&hl=zh-CN&oi=ao), [James Zou](https://scholar.google.com/citations?user=23ZXZvEAAAAJ&hl=zh-CN), [Jian Pei](https://scholar.google.com/citations?user=zIMEVKsAAAAJ&hl=en&oi=ao), [Kui Ren](https://scholar.google.com/citations?user=uuQA_rcAAAAJ&hl=en&oi=sra), [Amirata Ghorbani](https://scholar.google.com/citations?user=kuFQfwEAAAAJ&hl=en), [Jiachen T. Wang](https://scholar.google.com/citations?user=nvQOtgkAAAAJ&hl=en&oi=sra), ...



## Paper List

### 2025

| Venue      | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| NeurIPS'25 | Rescaled Influence Functions: Accurate Data Attribution in High Dimension | [paper](https://arxiv.org/pdf/2506.06656)  [code](https://github.com/ittai-rubinstein/rescaled-influence-functions) |   `DA`    |                                                              |
| NeurIPS'25 | A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning | [paper](https://arxiv.org/pdf/2505.19281)  [code](https://github.com/LDAORL/LDA-ORL) |   `DA`    |                                                              |
| NeurIPS'25 | IF-Guide: Influence Function-Guided Detoxification of LLMs   | [paper](https://arxiv.org/pdf/2506.01790) [code](https://github.com/ztcoalson/IF-Guide) |   `DA`    |                                                              |
| NeurIPS'25 | Efficient Data Selection at Scale via Influence Distillation |          [paper](https://arxiv.org/pdf/2505.19051)           | `DA` `DS` |                                                              |
| NeurIPS'25 | Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data | [paper](https://www.arxiv.org/pdf/2502.09969v3) [code](https://github.com/agarwalishika/NN-CIFT) |   `DA`    |                                                              |
| NeurIPS'25 | GraSS: Scalable Influence Function with Sparse Gradient Compression | [paper](https://arxiv.org/pdf/2505.18976) [code](https://github.com/TRAIS-Lab/GraSS) |   `DA`    |                                                              |
| NeurIPS'25 | Localized Data Shapley: Accelerating Valuation for Nearest Neighbor Algorithms |                                                              |   `DA`    |                                                              |
| NeurIPS'25 | Faithful Group Shapley Value                                 | [paper](https://arxiv.org/pdf/2505.19013)  [code](https://github.com/KiljaeL/Faithful_GSV) |   `DA`    |                                                              |
| NeurIPS'25 | DATE-LM: Benchmarking Data Attribution Evaluation for Large Language Models | [paper](https://arxiv.org/pdf/2507.09424)  [code](https://github.com/DataAttributionEval/DATE-LM) |   `DA`    | Benchmark                                                    |
| NeurIPS'25 | Final-Model-Only Data Attribution with a Unifying View of Gradient-Based Methods |          [paper](https://arxiv.org/pdf/2412.03906)           |   `DA`    |                                                              |
| NeurIPS'25 | Enhancing Training Data Attribution with Representational Optimization | [paper](https://www.arxiv.org/pdf/2505.18513)  [code](https://github.com/sunnweiwei/AirRep) |   `DA`    |                                                              |
| NeurIPS'25 | Group-Level Data Selection for Efficient Pretraining         | [paper](https://arxiv.org/pdf/2502.14709) [code](https://github.com/facebookresearch/Group-MATES) |   `DS`    |                                                              |
| NeurIPS'25 | Model-Free Graph Data Selection under Distribution Shift     | [paper](Model-Free Graph Data Selection under Distribution Shift)  [code](https://github.com/haidnguyen0909/LinearFGW/blob/main/main.py) |   `DS`    |                                                              |
| KDD'25     | On the Support Vector Effect in DNNs: Rethinking Data Selection and Attribution |   [paper](https://dl.acm.org/doi/10.1145/3690624.3709295)    | `DA` `DS` |                                                              |
| KDD'25     | Training Data Attribution: Was Your Model Secretly Trained On Data Created By Mine? |          [paper](https://arxiv.org/pdf/2409.15781)           |   `DA`    |                                                              |
| KDD'25     | Data Glitches Discovery using Influence-based Model Explanations |   [paper](https://dl.acm.org/doi/10.1145/3690624.3709285)    |   `DA`    |                                                              |
| KDD'25     | A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices |          [paper](https://arxiv.org/pdf/2505.16563)           |   `DS`    |                                                              |
| KDD'25     | Shapley Value-driven Data Pruning for Recommender Systems    | [paper](https://arxiv.org/pdf/2505.22057) [code](https://github.com/Forrest-Stone/SVV) | `DA` `DS` |                                                              |
| KDD'25     | Harnessing Influence Function in Explaining Graph Neural Networks |                                                              |   `DA`    |                                                              |
| ICML'25    | When Dynamic Data Selection Meets Data Augmentation: Achieving Enhanced Training Acceleration |          [paper](https://arxiv.org/pdf/2505.03809)           |   `DS`    |                                                              |
| ICML'25    | TAROT: Targeted Data Selection via Optimal Transport         | [paper](https://arxiv.org/pdf/2412.00420) [code](https://github.com/vita-epfl/TAROT) |   `DS`    |                                                              |
| ICML'25    | Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning |          [paper](https://arxiv.org/pdf/2502.01968)           |   `DS`    |                                                              |
| ICML'25    | Predictive Data Selection: The Data That Predicts Is the Data That Teaches | [paper](https://arxiv.org/pdf/2503.00808) [code](https://github.com/hkust-nlp/preselect) |   `DS`    |                                                              |
| ICML'25    | Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples | [paper](https://arxiv.org/pdf/2502.09650) [code](https://github.com/glorgao/SelectiveDPO) |   `DS`    |                                                              |
| ICML'25    | The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph |        [paper](https://www.arxiv.org/pdf/2410.12458)         |   `DS`    |                                                              |
| ICML'25    | LLM Data Selection and Utilization via Dynamic Bi-level Optimization |                                                              |   `DS`    |                                                              |
| ICML'25    | NICE: Non-differentiable Evaluation Metric-based Data Selection for Instruction Tuning |                                                              |   `DS`    |                                                              |
| ICML'25    | MASS: Mathematical Data Selection via Skill Graphs for Pretraining Large Language Models | [paper](https://arxiv.org/pdf/2503.14917) [code](https://github.com/lijiazheng0917/MASS) |   `DS`    |                                                              |
| ICML'25    | A Versatile Influence Function for Data Attribution with Non-Decomposable Loss |          [paper](https://arxiv.org/pdf/2412.01335)           |   `DA`    |                                                              |
| ICML'25    | Prediction via Shapley Value Regression                      |          [paper](https://arxiv.org/pdf/2505.04775)           |   `DA`    |                                                              |
| ICML'25    | Towards Robust Influence Functions with Flat Validation Minima |                                                              |   `DA`    |                                                              |
| SIGMOD'25  | Shapley Value Estimation based on Differential Matrix        | [paper](https://dl.acm.org/doi/pdf/10.1145/3709725#page=1.54) |   `DA`    |                                                              |
| SIGMOD'25  | Modyn: Data-Centric Machine Learning Pipeline Orchestration  |          [paper](https://arxiv.org/pdf/2312.06254)           |   `DS`    | *A pipeline to support data selection and retraining decisions in large-scale growing dataset environments.* |
| ICLR'25    | A Decade's Battle on Dataset Bias: Are We There Yet?         |      [paper](https://openreview.net/pdf?id=SctfBCLmWo)       |           |                                                              |
| ICLR'25    | How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning |      [paper](https://openreview.net/pdf?id=EUSkm2sVJ6)       |   `DA`    |                                                              |
| ICLR'25    | Data Shapley in One Training Run                             |      [paper](https://openreview.net/pdf?id=HD6bWcj87Y)       |   `DA`    |                                                              |
| ICLR'25    | Data Selection via Optimal Control for Language Models       |      [paper](https://openreview.net/pdf?id=dhAL5fy8wS)       |   `DS`    |                                                              |
| ICLR'25    | Capturing the Temporal Dependence of Training Data Influence |      [paper](https://openreview.net/pdf?id=uHLgDEgiS5)       |   `DA`    |                                                              |
| ICLR'25    | ADAM Optimization with Adaptive Batch Selection              |      [paper](https://openreview.net/pdf?id=BZrSCv2SBq)       |   `DS`    |                                                              |
| ICLR'25    | Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws |      [paper](https://openreview.net/pdf?id=aqok1UX7Z1)       |   `DS`    |                                                              |
| ICLR'25    | Adversarial Attacks on Data Attribution                      |      [paper](https://openreview.net/pdf?id=oJgIRwkIUB)       |   `DA`    |                                                              |
| ICLR'25    | An Efficient Framework for Crediting Data Contributors of Diffusion Models |      [paper](https://openreview.net/pdf?id=9EqQC2ct4H)       |   `DA`    |                                                              |
| ICLR'25    | Compute-Constrained Data Selection                           |      [paper](https://openreview.net/pdf?id=4es2oO9tw1)       |   `DS`    | *This work explores the question of data selection under computation constraints.* |
| ICLR'25    | Coreset Selection via Reducible Loss in Continual Learning   |      [paper](https://openreview.net/pdf?id=mAztx8QO3B)       |   `DS`    |                                                              |
| ICLR'25    | Data Pruning by Information Maximization                     |      [paper](https://openreview.net/pdf?id=93XT0lKOct)       |   `DS`    |                                                              |
| ICLR'25    | DataMan: Data Manager for Pre-training Large Language Models |      [paper](https://openreview.net/pdf?id=eNbA8Fqir4)       |           |                                                              |
| ICLR'25    | DICE: Data Influence Cascade in Decentralized Learning       |      [paper](https://openreview.net/pdf?id=2TIYkqieKw)       |   `DA`    |                                                              |
| ICLR'25    | Diffusion Attribution Score: Which Training Sample Determines Your Generation? |      [paper](https://openreview.net/pdf?id=kuutidLf6R)       |   `DA`    |                                                              |
| ICLR'25    | DRoP: Distributionally Robust Data Pruning                   |      [paper](https://openreview.net/pdf?id=fxv0FfmDAg)       |   `DS`    |                                                              |
| ICLR'25    | Enhancing Training Robustness through Influence Measure      |      [paper](https://openreview.net/pdf?id=KjBG4JNOc2)       |   `DA`    |                                                              |
| ICLR'25    | GMValuator: Similarity-based Data Valuation for Generative Models |      [paper](https://openreview.net/pdf?id=WncnpvJk83)       |   `DA`    |                                                              |
| ICLR'25    | Harnessing Diversity for Important Data Selection in Pretraining Large Language Models |      [paper](https://openreview.net/pdf?id=bMC1t7eLRc)       |   `DS`    |                                                              |
| ICLR'25    | Improving Pretraining Data Using Perplexity Correlations     |      [paper](https://openreview.net/pdf?id=huuKoVQnB0)       |           |                                                              |
| ICLR'25    | Influence Functions for Scalable Data Attribution in Diffusion Models |      [paper](https://openreview.net/pdf?id=esYrEndGsr)       |   `DA`    |                                                              |
| ICLR'25    | Label-Free Coreset Selection with Proxy Training Dynamics    |      [paper](https://openreview.net/pdf?id=yklJpvB7Dq)       |   `DS`    |                                                              |
| ICLR'25    | Precedence-Constrained Winter Value for Effective Graph Data Valuation |      [paper](https://openreview.net/pdf?id=tVRVE0OAyb)       |   `DA`    |                                                              |
| ICLR'25    | SAVA: Scalable Learning-Agnostic Data Valuation              |      [paper](https://openreview.net/pdf?id=0UCoWxPhQ4)       |   `DA`    |                                                              |
| ICLR'25    | Scalable Influence and Fact Tracing for Large Language Model Pretraining |      [paper](https://openreview.net/pdf?id=gLa96FlWwn)       |   `DA`    |                                                              |
| ICLR'25    | SEAL: Safety-enhanced Aligned LLM Fine-tuning via Bilevel Data Selection |      [paper](https://openreview.net/pdf?id=VHguhvcoM5)       |   `DA`    |                                                              |
| ICLR'25    | SelectFormer: Private and Practical Data Selection for Transformers |      [paper](https://openreview.net/pdf?id=C5sxQsqv7X)       |   `DS`    |                                                              |
| ICLR'25    | Severing Spurious Correlations with Data Pruning             |      [paper](https://openreview.net/pdf?id=Bk13Qfu8Ru)       |   `DS`    |                                                              |
| ICLR'25    | Shapley-Guided Utility Learning for Effective Graph Inference Data Valuation |      [paper](https://openreview.net/pdf?id=8X74NZpARg)       |   `DA`    | *This paper explores data valuation for test nodes and their neighbors during the inference of GNNs. Since there are no labels during testing, an additional utility function needs to be learned.* |
| ICLR'25    | Small-to-Large Generalization: Training Data Influences Models Consistently Across Scale |      [paper](https://openreview.net/pdf?id=79ZkWgY2FI)       |   `DA`    |                                                              |
| ICLR'25    | STAFF: Speculative Coreset Selection for Task-Specific Fine-tuning |      [paper](https://openreview.net/pdf?id=FAfxvdv1Dy)       |   `DS`    |                                                              |
| ICLR'25    | Structural-Entropy-Based Sample Selection for Efficient and Effective Learning |      [paper](https://openreview.net/pdf?id=xUMI52rrW7)       |   `DS`    |                                                              |
| ICLR'25    | TimeInf: Time Series Data Contribution via Influence Functions |      [paper](https://openreview.net/pdf?id=Vz0CWFMPUe)       |   `DA`    |                                                              |
| ICLR'25    | Efficient Top-m Data Values Identification for Data Selection |      [paper](https://openreview.net/pdf?id=lOfuvmi2HT)       |   `DA`    |                                                              |
| ICLR'25    | ZooProbe: A Data Engine for Evaluating, Exploring, and Evolving Large-scale Training Data for Multimodal LLMs |      [paper](https://openreview.net/pdf?id=T4LtGj7us1)       |           |                                                              |

### 2024

| Venue      | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| arXiv’24   | Towards Data Valuation via Asymmetric Data Shapley           | [paper](https://arxiv.org/pdf/2411.00388) [code](https://github.com/xzheng01/Asymmetric-Data-Shapley) |   `DA`    |                                                              |
| arXiv'24   | Disentangled Structural and Featural Representation for Task-Agnostic Graph Valuation |          [paper](https://arxiv.org/pdf/2408.12659)           |   `DA`    |                                                              |
| arXiv'24   | Distilling The Knowledge in Data Pruning                     |          [paper](https://arxiv.org/pdf/2403.07854)           |   `DS`    |                                                              |
| Openreview | Data Attribution for Multitask Learning                      |     [paper](https://openreview.net/forum?id=77zLqGGowO)      |   `DA`    |                                                              |
| Openreview | On the Inflation of KNN-Shapley Value                        |         [paper](https://arxiv.org/html/2405.17489v1)         |   `DA`    |                                                              |
| Openreview | Data Valuation for Graphs                                    |      [paper](https://openreview.net/pdf?id=VW21r9rTjE)       |   `DA`    |                                                              |
| Openreview | Generalized Group Data Attribution                           |      [paper](https://openreview.net/pdf?id=BQgAToASdX)       |   `DA`    |                                                              |
| NeurIPS'24 | GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration | [paper](https://openreview.net/pdf?id=232VcN8tSx) [code](https://github.com/Jiachen-T-Wang/GREATS) |   `DS`    |                                                              |
| NeurIPS'24 | Not All Tokens Are What You Need for Pretraining             |      [paper](https://openreview.net/pdf?id=0NMzBwqaAJ)       |   `DS`    |                                                              |
| NeurIPS'24 | Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution | [paper](https://openreview.net/pdf?id=ZdWTN2HOie) [code](https://github.com/chanwkimlab/amortized-attribution) [code](https://github.com/chanwkimlab/amortized-attribution) |   `DA`    |                                                              |
| NeurIPS'24 | Data Distribution Valuation                                  | [paper](https://arxiv.org/pdf/2410.04386) [code](https://github.com/XinyiYS/Data_Distribution_Valuation) |   `DA`    |                                                              |
| NeurIPS'24 | DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation |         [paper](https://arxiv.org/pdf/2306.02071v2)          |   `DA`    |                                                              |
| NeurIPS'24 | SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning |          [paper](https://arxiv.org/pdf/2405.00705)           |   `DA`    | *It first divide the data into clusters and compute the Shapley value of clusters, and then select representative data points inside cluster.* |
| NeurIPS'24 | 2D-OOB: Attributing Data Contribution through Joint Valuation Framework | [paper](https://arxiv.org/pdf/2408.03572) [code](https://github.com/YifanSun99/2d-oob) |   `DA`    |                                                              |
| NeurIPS'24 | A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective |      [paper](https://openreview.net/pdf?id=ZVrrPNqHFw)       |   `DA`    |                                                              |
| NeurIPS'24 | Training Data Attribution via Approximate Unrolling          |          [paper](https://arxiv.org/pdf/2405.12186)           |   `DA`    |                                                              |
| NeurIPS'24 | Data Attribution for Text-to-Image Models by Unlearning Synthesized Images |                                                              |   `DA`    |                                                              |
| NeurIPS'24 | Efficient Sketches for Training Data Attribution and Studying the Loss Landscape |                                                              |   `DA`    |                                                              |
| NeurIPS'24 | MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models |          [paper](https://arxiv.org/pdf/2406.06046)           |   `DS`    |                                                              |
| ICDE'24    | When Data Pricing Meets Non-cooperative  Game Theory         | [paper](https://ieeexplore.ieee.org/abstract/document/10597734) |   `DA`    |                                                              |
| arXiv'24   | Data Debiasing with Datamodels (D3M): Improving Subgroup Robustness via Data Selection | [paper](https://arxiv.org/pdf/2406.16846#page=1.34) [code](https://github.com/MadryLab/D3M) | `DS` `DA` |                                                              |
| KDD'24     | EcoVal: An Efficient Data Valuation Framework for Machine Learning | [paper](https://dl.acm.org/doi/pdf/10.1145/3637528.3672068) [code](https://github.com/respai-lab/ecoval) |   `DA`    | *For the efficiency of data valuation, this work first divide the data into clusters, and compute the cluster value with LOO. It then assign the individual data value inside a cluster through produce function.* |
| KDD'24     | Approximating Memorization Using Loss Surface Geometry for Dataset Pruning and Summarization | [paper](https://dl.acm.org/doi/pdf/10.1145/3637528.3671985) [code](https://github.com/AndAgio/SAMIS) | `DS` `DP` | *This paper shows memorization score is effective for data summarization / selection tasks, and proposes to approximate memorization with SGD.* |
| KDD'24     | Scalable Rule Lists Learning with Sampling                   | [paper](https://dl.acm.org/doi/pdf/10.1145/3637528.3671989) [code](https://github.com/VandinLab/SamRuLe) |   `DP`    | *This work proposes to learn the approximately optimal rule set through sampling by preserving both accuracy and efficiency.* |
| KDD'24     | AIM: Attributing, Interpreting, Mitigating Data Unfairness   | [paper](https://dl.acm.org/doi/abs/10.1145/3637528.3671797) [code](https://github.com/ZhiningLiu1998/AIM) |   `DP`    |                                                              |
| KDD'24     | CAT: Interpretable Concept-based Taylor Additive Models      | [paper](https://dl.acm.org/doi/abs/10.1145/3637528.3672020) [code](https://github.com/vduong143/CAT-KDD-2024) |           |                                                              |
| KDD'24     | Dataset Regeneration for Sequential Recommendation           | [paper](https://dl.acm.org/doi/10.1145/3637528.3671841) [code](https://github.com/USTC-StarTeam/DR4SR) |   `DS`    |                                                              |
| arXiv'24   | What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions |     [paper](https://arxiv.org/pdf/2405.13954#page=1.31)      |   `DA`    |                                                              |
| arXiv'24   | CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning |          [paper](https://arxiv.org/pdf/2406.11730)           |   `DA`    |                                                              |
| ICML'24    | QuRating: Selecting High-Quality Data for Training Language Models | [paper](https://arxiv.org/pdf/2402.09739) [code](https://github.com/princeton-nlp/QuRating) |   `DS`    |                                                              |
| ICML'24    | Scaling Laws for the Value of Individual Data Points in Machine Learning | [paper](https://arxiv.org/pdf/2405.20456) [code](https://github.com/iancovert/data-scaling) |   `DA`    | *This work proposes individual scaling law for distinguishing how the marginal contribution of a data point varies as the dataset size growing. It then proposes two methods to estimate the individual scaling law.* |
| ICML'24    | Rethinking Data Shapley for Data Selection Tasks: Misleads and Merits |          [paper](https://arxiv.org/pdf/2405.03875)           | `DA` `DS` | *In general cases without considering the structural assumptions of utility functions, Data Shapley’s performance in data selection tasks can be no better than that of random guessing. It proposes a heuristic for predicting Data Shapley’s optimality for data selection.* |
| ICML'24    | Incorporating Information into Shapley Values:  Reweighting via a Maximum Entropy Approach |      [paper](https://openreview.net/pdf?id=DwniHlwcOB)       |   `DA`    |                                                              |
| ICML'24    | Distributionally Robust Data Valuation                       | [paper](https://openreview.net/pdf?id=mbBehLOAqR) [code](https://github.com/xqlin98/Distributionally-Robust-Data-Valuation) |   `DA`    |                                                              |
| ICML'24    | Helpful or Harmful Data?  Fine-tuning-free Shapley Attribution for Explaining Language Model Predictions | [paper](https://arxiv.org/pdf/2406.04606v1) [code](https://github.com/JTWang2000/FreeShap) |   `DA`    | *It proves that Shapley value shows better robustness compared to LOO and proposes FreeShap to estimate Shapley using eNTK without retraining.* |
| ICML'24    | Efficient Adversarial Contrastive Learning via Robustness-Aware Coreset Selection | [paper](https://openreview.net/pdf?id=WSpPC1Jm0p) [code](https://github.com/JTWang2000/FreeShap) |   `DA`    |                                                              |
| ICML'24    | Optimal Coresets for Low-Dimensional Geometric Median        |      [paper](https://openreview.net/pdf?id=8iWDWQKxJ1)       |   `DS`    |                                                              |
| ICML'24    | No Dimensional Sampling Coresets for Classification          | [paper](https://proceedings.mlr.press/v235/alishahi24a.html) |   `DS`    |                                                              |
| ICML'24    | Coresets for Multiple $ℓ_𝑝$ Regression                       | [paper](https://proceedings.mlr.press/v235/woodruff24a.html) |   `DS`    |                                                              |
| ICML'24    | Deletion-Anticipative Data Selection with a Limited Budget   |      [paper](https://openreview.net/pdf?id=ecvuJWE1YY)       |   `DS`    |                                                              |
| ICML'24    | Data-Efficient Learning via Clustering-Based Sensitivity Sampling: Foundation Models and Beyond |      [paper](https://openreview.net/pdf?id=WUQ4YzIQt2)       |   `DS`    |                                                              |
| ICML'24    | Refined Coreset Selection: Towards Minimal Coreset Size under Model Performance Constraints | [paper](https://openreview.net/pdf?id=yb5xV8LFDq) [code](https://github.com/xiaoboxia/LBCS) |   `DS`    |                                                              |
| ICML'24    | Mind the Boundary: Coreset Selection via Reconstructing the Decision Boundary |      [paper](https://openreview.net/pdf?id=hWng0GXeE4)       |   `DS`    | *This work proposes to select a coreset that maintains the decision boundary of model trained on full dataset. It measures the distance between a sample to its nearest decision boundary and selects data based on this distance.* |
| ICML'24    | DsDm: Dataset Selection with Datamodels                      | [paper](https://proceedings.mlr.press/v235/engstrom24a.html) |   `DS`    | *DsDm converts the data selection problem into loss minimization problem in target data. It then uses linear datamodel to approximate the loss mapping and select the bottom-k samples with smallest estimated loss.* |
| ICML'24    | BWS: Best Window Selection Based on Sample Scores for Data Pruning across Broad Ranges |                                                              |   `DS`    |                                                              |
| ICML'24    | LESS: Selecting Influential Data for Targeted Instruction Tuning | [paper](https://arxiv.org/pdf/2402.04333v1) [code](https://github.com/princeton-nlp/LESS) |   `DS`    |                                                              |
| ICML'24    | Exploiting Negative Samples: A Catalyst for Cohort Discovery in Healthcare Analytics |  [paper](https://proceedings.mlr.press/v235/zheng24c.html)   | `DA` `DP` | *This work proposes to leverage data Shapley value to value each data in negative sample, and employs manifold learning and clustering to find influential patterns in negative samples.* |
| CVPR'24    | The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes | [paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Ko_The_Mirrored_Influence_Hypothesis_Efficient_Data_Influence_Estimation_by_Harnessing_CVPR_2024_paper.pdf) |   `DS`    |                                                              |
| VLDB'24    | A Comprehensive Study of Shapley Value in Data Analytics     |          [paper](https://arxiv.org/pdf/2412.01460)           |   `DA`    |                                                              |
| VLDB'24    | Counterfactual Explanation of Shapley Value in Data Coalitions | [paper](https://www.vldb.org/pvldb/vol17/p3332-si.pdf) [code](https://github.com/michelleeesi/shapley_counterfactual) |   `DA`    | *If the Shapley value of data owner A is higher than B, the counterfactual explanation aims to find a smallest subset of data in A that such that moving it from A to B makes  Shapley value of A less than that of B. This work proposes a greedy based search to find the counterfactual.* |
| VLDB'24    | P-Shapley: Shapley Values on Probabilistic Classifiers       | [paper](https://www.vldb.org/pvldb/vol17/p1737-liu.pdf) [code](https://github.com/ZJU-DIVER/P-Shapley) |   `DA`    | *This paper introduces P-Shapley with raw probability (instead of accuracy) as utility function and proposes calibration function to enlarge the utility change when the predicted probability is high.* |
| VLDB'24    | MetaStore: Analyzing Deep Learning Meta-Data at Scale        |   [paper](https://www.vldb.org/pvldb/vol17/p1446-cao.pdf)    | `DA` `DP` |                                                              |
| VLDB'24    | Optimizing Data Acquisition to Enhance Machine Learning Performance | [paper](https://www.vldb.org/pvldb/vol17/p1310-bao.pdf) [code](https://github.com/rmitbggroup/da-ml) |   `DS`    |                                                              |
| VLDB'24    | MisDetect: Iterative Mislabel Detection using Early Loss     | [paper](https://www.vldb.org/pvldb/vol17/p1159-chai.pdf) [code](https://github.com/anonymous-repo1/misdetect) |   `DA`    |                                                              |
| VLDB'24    | Outlier Summarization via Human Interpretable Rules          | [paper](https://dl.acm.org/doi/10.14778/3654621.3654627) [code](https://github.com/baodaBBji/anonymous-Tech-Report) |   `DP`    | *It trains a decision tree model to summarize the rule patterns of outliers.* |
| VLDB'24    | Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities | [paper](https://arxiv.org/pdf/2402.01071.pdf) [code](https://github.com/UIC-InDeXLab/Chameleon) |   `DS`    | *It uses generative AI for augmentation, ensuring that the generated data covering the original data distribution with a smallest size.* |
| VLDB'24    | DataPrice: An Interactive System for Pricing Datasets in Data Marketplaces |   [paper](https://www.vldb.org/pvldb/vol17/p4433-liu.pdf)    |   `DA`    |                                                              |
| SIGMOD'24  | Discovering Top-k Relevant and Diversified Rules             |     [paper](https://mxieaa.github.io/paper/SIGMOD25.pdf)     |   `DP`    |                                                              |
| SIGMOD'24  | Rock: Cleaning Data by Embedding ML in Logic Rules           | [paper](https://dl.acm.org/doi/abs/10.1145/3626246.3653372)  | `DP` `DA` | *Rock implements a uniform data cleaning framework that unifies ML and logic deduction.* |
| SIGMOD'24  | Data Acquisition for Improving Model Confidence              |     [paper](https://dl.acm.org/doi/pdf/10.1145/3654934)      |   `DS`    |                                                              |
| SIGMOD'24  | Controllable Tabular Data Synthesis Using Diffusion Models   |       [paper](https://dl.acm.org/doi/10.1145/3639283)        |   `DS`    |                                                              |
| SIGMOD'24  | Fast Shapley Value Computation in Data Assemblage Tasks as Cooperative Simple Games | [paper](https://xuc.me/file/paper/SIGMOD24b.pdf) [code](https://github.com/IDEAL-Lab/shapley-value-simple-game) |   `DA`    | *It assigns a Shapley score for data owners and their corresponding datasets in data market.* |
| WWW'24     | Exploring Neural Scaling Law and Data Pruning Methods For Node Classification on Large-scale Graphs | [paper](https://dl.acm.org/doi/pdf/10.1145/3589334.3645571) [code](https://github.com/joneswong/GNSL) |   `DS`    | *This work selects training nodes that are similar to test nodes by minimizing their bottleneck distance. To avoid bias caused by trivial selection, it uses a greedy alg. to assure the representativeness of selected nodes.* |
| AAAI'24    | DeRDaVa: Deletion-Robust Data Valuation for Machine Learning |          [paper](https://arxiv.org/pdf/2312.11413)           |   `DA`    |                                                              |
| AAAI'24    | Quality-Diversity Generative Sampling for Learning with Synthetic Data | [paper](https://ojs.aaai.org/index.php/AAAI/article/download/29955/31670) [code](https://github.com/Cylumn/qd-generative-sampling) |   `DS`    |                                                              |
| AAAI'24    | Approximating the Shapley Value without Marginal Contributions | [paper](https://ojs.aaai.org/index.php/AAAI/article/download/29225/30311) |   `DA`    | *It transfer Shapley value by $\phi_i = \phi_i^+ + \phi_i^-$. It samples coalitions and update $\phi_i^+$ and $\phi_i^-$ separately.* |
| WSDM'24    | FairIF: Boosting Fairness in Deep Learning via Influence Functions with Validation Set Sensitive Attributes | [paper](https://dl.acm.org/doi/pdf/10.1145/3616855.3635844?casa_token=0-2Cnoe2_kQAAAAA:kOtBF3rsnlzcX0tv-6og4n5LFG-xBbphXH_Aga45OeQUyJUpQBh4Bkoydcu2gf_8rFej0ljKUBFz) |   `DA`    |                                                              |
| WSDM'24    | Efficient, Direct, and Restricted Black-Box Graph Evasion Attacks to Any-Layer Graph Neural Networks via Influence Function | [paper](https://dl.acm.org/doi/pdf/10.1145/3616855.3635826?casa_token=p1rDbOded6oAAAAA:-8uNJw5R4pGO-f4J02uKQZdOsOfEITqeF6nh6dh9tcriDDItmSzlZahoeB9Q6na07Eywpnq7oNR1) [code](https://github.com/ventr1c/InfAttack) |   `DA`    |                                                              |
| ICLR'24    | Faster Approximation of Probabilistic and Distributional Values via Least Squares | [paper](https://openreview.net/pdf?id=lvSMIsztka) [code](https://github.com/watml/fastpvalue) |   `DA`    |                                                              |
| ICLR'24    | "What Data Benefits My Classifier?" Enhancing Model Performance and Interpretability through Influence-Based Data Selection | [paper](https://openreview.net/pdf?id=HE9eUQlAvo) [code](https://github.com/anshuman23/InfDataSel) | `DS` `DA` | *It extends influence function considering utility, fairness and robustness. It trains a decision tree to further estimate and interpret the influence score.* |
| ICLR'24    | Canonpipe: Data Debugging with Shapley Importance over Machine Learning Pipelines | [paper](https://openreview.net/pdf?id=qxGXjWxabq) [code](https://github.com/easeml/datascope) |   `DA`    | *It explores data valuation on raw data before preprocessing. It uses data provenance in ML pipelines and proposes data Shapley under a KNN approximation.* |
| ICLR'24    | Time Travel in LLMs: Tracing Data Contamination in Large Language Models | [paper](https://openreview.net/pdf?id=2Rwq6c3tvr) [code](https://github.com/shahriargolchin/time-travel-in-llms) |   `DA`    | *Data contamination means the presence of test data from downstream tasks in the pre-training data of LLMs. This work explore both instance and partition level methods to identify potential contamination.* |
| ICLR'24    | GIO: Gradient Information Optimization for Training Dataset Selection | [paper](https://openreview.net/pdf?id=3NnfJnbJT2) [code](https://github.com/daeveraert/gradient-information-optimization) |   `DA`    | *GIO selects a small subset of data from large source data by minimizing the KL divergence between the target distribution and subset.* |
| ICLR'24    | Intriguing Properties of Data Attribution on Diffusion Models | [paper](https://openreview.net/pdf?id=vKViCoKGcB) [code](https://github.com/sail-sg/D-TRAK) |   `DA`    | *This paper proposes D-TRAK to attribute images generated by diffusion models back to the training data.* |
| ICLR'24    | D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning | [paper](https://openreview.net/pdf?id=thbtoAkCe9) [code](https://github.com/adymaharana/d2pruning) |   `DS`    | *A data pruning method that takes diversity into consideration. It is implemented by forward and reverse message passing in the KNN graph.* |
| ICLR'24    | Effective pruning of web-scale datasets based on complexity of concept clusters | [paper](https://openreview.net/pdf?id=CtOA9aN8fr) [code](https://github.com/amro-kamal/effective_pruning) |   `DS`    |                                                              |
| ICLR'24    | Towards a statistical theory of data selection under weak supervision |      [paper](https://openreview.net/pdf?id=HhfcNgQn6p)       |   `DS`    |                                                              |
| ICLR'24    | Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs | [paper](https://openreview.net/pdf?id=QmYNBVukex) [code](https://anonymous.4open.science/r/DV4LLM-D761/) |   `DS`    |                                                              |
| ICLR'24    | DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models | [paper](https://openreview.net/pdf?id=9m02ib92Wz) [code](https://github.com/ykwon0407/DataInf) |   `DA`    | *DataInf approximate influence function by swapping the order of the matrix inversion and average calculation.* |
| ICLR'24    | What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning |      [paper](https://openreview.net/pdf?id=BTKAeLqLMw)       |   `DS`    |                                                              |
| ICLR'24    | Real-Fake: Effective Training Data Synthesis Through Distribution Matching | [paper](http://arxiv.org/pdf/2310.10402.pdf) [code](http://arxiv.org/pdf/2310.10402.pdf) |   `DS`    |                                                              |
| ICLR'24    | InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning | [paper](https://openreview.net/pdf?id=C61sk5LsK6) [code](https://github.com/NUS-HPC-AI-Lab/InfoBatch) |   `DS`    | *InfoBatch uses training loss to prune well-learned samples in each epoch and estimate gradient distribution for unbiased learning.* |
| arXiv'24   | A Decade's Battle on Dataset Bias: Are We There Yet?         | [paper](https://arxiv.org/pdf/2403.08632.pdf) [code](http://github.com/liuzhuang13/bias) |   `DS`    |                                                              |
| arXiv'24   | On the Cause of Unfairness: A Training Sample Perspective    |       [paper](https://arxiv.org/pdf/2306.17828v2.pdf)        |   `DA`    | *The fairness influence can be computed by replacing the training sample with its concept counterfactual sample.* |



### 2023

| Venue            | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :--------------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| arXiv'23         | Accelerated Shapley Value Approximation for Data Evaluation  |          [paper](https://arxiv.org/pdf/2311.05346)           |   `DA`    | *Not all coalition sizes are evaluated, small coalitions may introduce noise and large ones may have little contributions. To estimate the effect of coalitions with size k, about O(1 / k^2) sample coalitions is sufficient.* |
| arXiv'23         | The Journey, Not the Destination: How Data Guides Diffusion Models | [paper](http://arxiv.org/pdf/2312.06205.pdf) [code](https://github.com/MadryLab/journey-TRAK) |   `DA`    | -                                                            |
| NeurIPS'23       | The Memory Perturbation Equation: Understanding Model’s Sensitivity to Data | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/550ab405d0addd3de5b70e57b44878df-Paper-Conference.pdf) [code](https://github.com/team-approx-bayes/memory-perturbation) | `DA` `DP` | -                                                            |
| NeurIPS'23       | Theoretical and Practical Perspectives on what Influence Functions Do |      [paper](https://openreview.net/pdf?id=gGl0n7Onug)       |   `DA`    | *This work discusses some problematic assumptions of IF. While most of them can be addressed, IF can predict perturbated param accurately for a limited amount of time-steps.* |
| NeurIPS'23       | Data Selection for Language Models via Importance Resampling | [paper](https://openreview.net/pdf?id=uPSQv0leAu) [code](https://github.com/p-lambda/dsir) | `DS` `DA` | *It selects data satisfying a target distribution from raw data by reducing KL divergence to the target over random selection.* |
| NeurIPS'23       | Model Shapley: Equitable Model Valuation with Black-box Access | [paper](https://openreview.net/pdf?id=Y6IGTNMdLT) [code](https://github.com/XinyiYS/ModelShapley) |   `DA`    | -                                                            |
| NeurIPS'23       | Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation |      [paper](https://openreview.net/pdf?id=FAZ3i0hvm0)       |   `DA`    | *Extend KNN-Shapley while considering data privacy.*         |
| NeurIPS'23       | GEX: A flexible method for approximating influence via Geometric Ensemble | [paper](https://openreview.net/attachment?id=tz4ECtAu8e&name=pdf) [code](https://github.com/sungyubkim/gex) |   `DA`    | -                                                            |
| NeurIPS'23       | Efficient Data Subset Selection to Generalize Training Across Models: Transductive and Inductive Networks | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/0f25eb6e9dc26c933a5d7516abf1eb8c-Paper-Conference.pdf) [code](https://github.com/structlearning/subselnet) |   `DS`    | -                                                            |
| NeurIPS'23       | Data Pruning via Moving-one-Sample-out                       | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/3abe23bf7e295b44369c24465d68987a-Paper-Conference.pdf) |   `DS`    | *This work proposes a Moso score (similar to LOO) and an approximates it using gradient over all training epochs.* |
| NeurIPS'23       | Towards Free Data Selection with General-Purpose Models      | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/047682108c3b053c61ad2da5a6057b4e-Paper-Conference.pdf) [code](https://github.com/yichen928/FreeSel) |   `DS`    | -                                                            |
| NeurIPS'23       | Towards Accelerated Model Training via Bayesian Data Selection | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/1af3e0bf5905e33789979f666c31192d-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NeurIPS'23       | Robust Data Valuation with Weighted Banzhaf Values           | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/bdb0596d13cfccf2db6f0cc5280d2a3f-Paper-Conference.pdf) |   `DA`    | -                                                            |
| NeurIPS'23       | UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with Vision-Language Models | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/06d5f1fe6509b001e6d4e0ec1afd83dd-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NeurIPS'23       | Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/c142c14699223f7417cad706fd6f652e-Paper-Conference.pdf) [code](https://github.com/ruoxi-jia-group/projektor) |   `DS`    | *Given publicly known pilot data from different data sources, it returns the optimal combination of data sources.* |
| NeurIPS'23       | Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ebb6bee50913ba7e1efeb91a1d47a002-Paper-Conference.pdf) [code](https://github.com/kaist-dmlab/Prune4Rel) |   `DS`    | -                                                            |
| NeurIPS'23       | Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/81cca94f16f20d5548c76c3344b27dea-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NeurIPS'23       | Core-sets for Fair and Diverse Data Summarization            | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/f980ba94f513168f2b292f58aef929ec-Paper-Conference.pdf) [code](https://github.com/microsoft/coresets-fair-diverse) | `DS` `DP` | *It selects a fixed size of coreset for different groups of data while preserving diversity.* |
| NeurIPS'23       | Retaining Beneficial Information from Detrimental Data for Neural Network Repair | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/964b1c8dd5667fd647c09c8772829fd1-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NeurIPS'23       | Expanding Small-Scale Datasets with Guided Imagination       | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/f188a55392d3a7509b0b27f8d24364bb-Paper-Conference.pdf) [code](https://github.com/Vanint/DatasetExpansion) |   `DS`    | -                                                            |
| NeurIPS'23       | Error Discovery By Clustering Influence Embeddings           | [paper](https://openreview.net/pdf?id=yBVLXvJ1sb) [code](https://github.com/adebayoj/infembed) |   `DA`    | *This work cluster influence embedding (a low dimension of influence vector of training samples) for all test samples to summarize the prediction error.* |
| NeurIPS'23       | HiBug: On Human-Interpretable Model Debug                    | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/0f53ecc0d36a5d5d3d3e94d42c4b23ca-Paper-Conference.pdf) [code](https://github.com/cure-lab/HiBug) | `DP` `DS` | -                                                            |
| NeurIPS'23       | Skill-it! A data-driven skills framework for understanding and training language models | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/70b8505ac79e3e131756f793cd80eb8d-Paper-Conference.pdf) [code](https://github.com/HazyResearch/skill-it) | `DP` `DS` | -                                                            |
| ICML'23          | Discover and Cure: Concept-aware Mitigation of Spurious Correlation | [paper](https://openreview.net/pdf?id=QDxtrlPmfB) [code](https://github.com/Wuyxin/DISC) | `DS` `DA` | *Discover spurious correlation from concept level and perform concept-based data augmentation to mitigate bias.* |
| ICML'23          | TRAK: Attributing Model Behavior at Scale                    | [paper](https://openreview.net/pdf?id=PBRArApxMh) [code](https://github.com/MadryLab/trak) |   `DA`    | *TRAK first defines a Newton approximation to estimate LOO for logistic regression and then extends it to NNs (including CLIP, mT5) by view them as the linear model acting on input gradient.* |
| ICML'23          | RGE: A Repulsive Graph Rectification for Node Classification via Influence | [paper](https://proceedings.mlr.press/v202/song23f/song23f.pdf) [code](https://github.com/Jaeyun-Song/RGE.git) |   `DA`    | *RGE identifies a group of negative edges that are most harmful for GNNs. It iteratively selects negative edges by their individual influence and prefers distant edges first.* |
| ICML'23          | Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value | [paper](https://proceedings.mlr.press/v202/kwon23e/kwon23e.pdf) [code](https://github.com/ykwon0407/dataoob) |   `DA`    | *Data-OOB measures the average score when a datum (OOB data) is not selected in the bootstrap dataset.* |
| ICML'23          | 2D-Shapley: A Framework for Fragmented Data Valuation        | [paper](https://proceedings.mlr.press/v202/liu23s/liu23s.pdf) |   `DA`    |                                                              |
| ICML'23          | Towards Sustainable Learning: Coresets for Data-efficient Deep Learning | [paper](https://proceedings.mlr.press/v202/yang23g/yang23g.pdf) [code](https://github.com/bigml-cs-ucla/crest) |   `DS`    | -                                                            |
| ICML'23          | “Why did the Model Fail?”: Attributing Model Performance Changes to  Distribution Shifts | [paper](https://proceedings.mlr.press/v202/zhang23ai/zhang23ai.pdf) [code](https://github.com/MLforHealth/expl_perf_drop) |   `DA`    |                                                              |
| ICML'23 Workshop | Training on Thin Air: Improve Image Classification with Generated Data | [paper](https://dmlr.ai/assets/accepted-papers/9/CameraReady/Diffusion_Inversion_DMLR_ICML2023_compressed.pdf) |   `DS`    | -                                                            |
| ICML'23 Workshop | Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation | [paper](https://dmlr.ai/assets/accepted-papers/49/CameraReady/icml.pdf) [code](https://github.com/MadryLab/dataset-interfaces) | `DA` `DS` | -                                                            |
| VLDB'23          | Equitable Data Valuation Meets the Right to Be Forgotten in Model Markets | [paper](https://www.vldb.org/pvldb/vol16/p3349-liu.pdf) [code](https://github.com/ZJU-DIVER/ValuationMeetsRTBF) |   `DA`    | -                                                            |
| VLDB'23          | Computing Rule-Based Explanations by Leveraging Counterfactuals | [paper](https://www.vldb.org/pvldb/vol16/p420-geng.pdf) [code](https://github.com/GibbsG/GeneticCF) |   `DP`    | -                                                            |
| VLDB'23          | Data Collection and Quality Challenges for Deep Learning     |  [paper](https://www.vldb.org/pvldb/vol13/p3429-whang.pdf)   | `DS` `DA` | -                                                            |
| SIGMOD'23        | GoodCore: Coreset Selection over Incomplete Data for Data-effective and Data-efficient Machine Learning |     [paper](https://dl.acm.org/doi/pdf/10.1145/3589302)      |   `DS`    | *GoodCore selects a coreset that achieves expected low gradient approximation error among all possible worlds of missing data.* |
| SIGMOD'23        | XInsight: eXplainable Data Analysis Through The Lens of Causality |        [paper](https://arxiv.org/pdf/2207.12718.pdf)         |   `DP`    | -                                                            |
| SIGMOD'23        | HybridPipe: Combining Human-generated and Machine-generated Pipelines for Data Preparation | [paper](https://dbgroup.cs.tsinghua.edu.cn/ligl/papers/haipipe-acm.pdf) [code](https://github.com/ruc-datalab/Haipipe) | `DS` `DP` | -                                                            |
| SIGMOD'23        | Saga: A Scalable Framework for Optimizing Data Cleaning  Pipelines for Machine Learning Applications |     [paper](https://dl.acm.org/doi/abs/10.1145/3617338)      |           |                                                              |
| ACL'23           | Data Selection for Fine-tuning Large Language Models  Using Transferred Shapley Values |          [paper](https://arxiv.org/pdf/2306.10165)           |   `DA`    |                                                              |
| arXiv'23         | Simfluence: Modeling the influence of individual training examples by simulating training runs |          [paper](https://arxiv.org/pdf/2303.08114)           |   `DS`    | *Trains a simulator that generates a time series that predicts what the loss on $z_{test}$ would be after each step of the training run (a loss trajectory).* |
| ICLR'23          | Data Valuation Without Training of a Model                   | [paper](https://openreview.net/pdf?id=XIzO8zr-WbM) [code](https://github.com/JJchy/CG_score) |   `DA`    | *It proposes a score to measures the gap in data complexity where a certain data instance is removed from the full dataset.* |
| ICLR'23          | Distilling Model Failures as Directions in Latent Space      | [paper](https://openreview.net/pdf?id=99RpBVpLiX) [code](https://github.com/MadryLab/failure-directions) | `DS` `DP` | -                                                            |
| ICLR'23          | LAVA: Data Valuation without Pre-Specified Learning Algorithms | [paper](https://openreview.net/pdf?id=JJuP86nBl4q) [code](https://github.com/ruoxi-jia-group/LAVA) |   `DA`    | *LAVA uses a Wasserstein distance to estimate the upper bound of test performance. It values a training sample by its sensitivity to the distance.* |
| ICLR'23          | Concept-level Debugging of Part-Prototype Networks           | [paper](https://openreview.net/pdf?id=oiwXWPDTyNk) [code](https://github.com/abonte/protopdebug) |   `DP`    | -                                                            |
| ICLR'23          | Dataset Pruning: Reducing Training Data by Examining Generalization Influence |      [paper](https://openreview.net/pdf?id=4wZiAXD29TQ)      |   `DS`    | -                                                            |
| ICLR'23          | Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning | [paper](https://openreview.net/pdf?id=7D5EECbOaf9) [code](https://github.com/tmllab/Moderate-`DS`) |   `DS`    | -                                                            |
| ICLR'23          | Learning to Estimate Shapley Values with Vision Transformers | [paper](https://openreview.net/pdf?id=5ktFNz_pJLK) [code](https://github.com/suinleelab/vit-shapley) |   `DA`    | -                                                            |
| ICLR'23          | Characterizing the Influence of Graph Elements               | [paper](https://openreview.net/pdf?id=51GXyzOKOp) [code](https://github.com/Cyrus9721/Characterizing_graph_influence) |   `DA`    | *Introduce influence function into graphs, considering node- and edge-removal influence and the linear SGC model.* |
| ICLR'23          | Dataset pruning: Reducing training data by examining generalization influence. |      [paper](https://openreview.net/pdf?id=4wZiAXD29TQ)      |   `DA`    |                                                              |
| ICDE'23          | Automatic Feasibility Study via Data Quality Analysis for ML: A Case-Study on Label Noise | [paper](https://arxiv.org/pdf/2010.08410.pdf) [code](https://github.com/easeml/snoopy) |   `DP`    | -                                                            |
| ICDE'23          | Detection of Groups with Biased Representation in Ranking    |        [paper](https://arxiv.org/pdf/2301.00719.pdf)         |   `DA`    | -                                                            |
| AAAI'23          | Fundamentals of Task-Agnostic Data Valuation                 | [paper](https://ojs.aaai.org/index.php/AAAI/article/view/26106/25878) |   `DA`    | -                                                            |
| AAAI'23          | Interpreting Unfairness in Graph Neural Networks via Training Node Attribution | [paper](https://ojs.aaai.org/index.php/AAAI/article/view/25905/25677) [code](https://github.com/yushundong/BIND) |   `DA`    | *This work proposes a Probabilistic Distribution Disparity to define node-contributed model bias and use gradient approximation to estimate node-level bias.* |
| AAAI'23          | Interpreting Unfairness in Graph Neural Networks via Training Node Attribution | [paper](https://ojs.aaai.org/index.php/AAAI/article/download/25905/25677) [code](https://github.com/yushundong/BIND) |   `DA`    |                                                              |
| WWW'23           | GIF: A General Graph Unlearning Strategy via Influence Function | [paper](https://arxiv.org/pdf/2304.02835.pdf) [code](https://github.com/wujcan/GIF-torch/) |   `DA`    | *GIF extends influence function to graph data by considering both the directly affected node(s) and the influenced neighborhoods.* |
| AISTATS'23       | Data Banzhaf: A Robust Data Valuation Framework for Machine Learning | [paper](https://proceedings.mlr.press/v206/wang23e/wang23e.pdf) |   `DA`    | -                                                            |
| arXiv'23         | Data-Juicer: A One-Stop Data Processing System for Large Language Models | [paper](https://arxiv.org/pdf/2309.02033.pdf) [code](https://github.com/alibaba/data-juicer) | `DS` `DP` | -                                                            |
| arXiv'23         | Simﬂuence: Modeling the inﬂuence of individual training examples by simulating training runs |          [paper](https://arxiv.org/pdf/2303.08114)           |   `DA`    |                                                              |
| arXiv'23         | Studying Large Language Model Generalization with Influence Functions |        [paper](https://arxiv.org/pdf/2308.03296.pdf)         |   `DA`    | -                                                            |
| TMLR'23          | Synthetic Data from Diffusion Models Improves ImageNet Classification |        [paper](https://arxiv.org/pdf/2304.08466.pdf)         |   `DS`    | -                                                            |

### 2022

| Venue      | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| NeurIPS'22 | CS-SHAPLEY: Class-wise Shapley Values for Data Valuation in Classification | [paper](https://openreview.net/pdf?id=KTOcrOR5mQ9) [code](https://github.com/stephanieschoch/cs-shapley) |   `DA`    |                                                              |
| NeurIPS'22 | Beyond neural scaling laws: beating power law scaling via data pruning |      [paper](https://openreview.net/pdf?id=UmvSlP-PyV)       |   `DS`    |                                                              |
| NeurIPS'22 | Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP | [paper](https://openreview.net/pdf?id=LTCBavFWp5C) [code](https://github.com/mlfoundations/clip_quality_not_quantity) |   `DS`    |                                                              |
| NeurIPS'22 | Quantifying memorization across neural language models       | [paper](https://arxiv.org/pdf/2202.07646.pdf?trk=public_post_comment-text) |   `DA`    |                                                              |
| ICML'22    | Measuring the Effect of Training Data on Deep Learning Predictions via Randomized Experiments | [paper](https://proceedings.mlr.press/v162/lin22h/lin22h.pdf) |   `DA`    | *It proposes the AME score $E_S[U(S\cup {z})-U(S)]$ with $S$ being a random set. The AME score can be approximated by a LASSO model.* |
| ICML'22    | Meaningfully Debugging Model Mistakes using Conceptual Counterfactual Explanations | [papeer](https://proceedings.mlr.press/v162/abid22a/abid22a.pdf) [code](https://github.com/mertyg/debug-mistakes-cce) | `DS` `DP` | *It learns CAV and move those misclassified training samples toward the direction of CAV.* |
| ICML'22    | Datamodels: Predicting Predictions from Training Data        | [paper](https://proceedings.mlr.press/v162/ilyas22a/ilyas22a.pdf) [code](https://github.com/MadryLab/datamodels-data) |   `DA`    | *Datamodels learns a linear model to predict the model output on one test data. It takes as input the one-hot mask of training samples.* |
| ICML'22    | Prioritized Training on Points that are learnable, Worth Learning, and Not Yet Learnt | [paper](https://proceedings.mlr.press/v162/mindermann22a/mindermann22a.pdf) [code](https://github.com/OATML/RHO-Loss) |   `DS`    |                                                              |
| ICML'22    | Achieving Fairness at No Utility Cost via Data Reweighing with Influence | [paper](https://proceedings.mlr.press/v162/li22p/li22p.pdf) [code](https://github.com/brandeis-machine-learning/influence-fairness) |   `DA`    | *It employs DP and EOP to compute IF and performs soft reweighing on training samples. The proof of no-utility-degradation is provided.* |
| ICML'22    | DAVINZ: Data Valuation using Deep Neural Networks at Initialization | [paper](https://proceedings.mlr.press/v162/wu22j/wu22j.pdf)  |   `DA`    | *It uses NTK-based bound to approximate validation performance without training.* |
| ICML'22    | Understanding Instance-Level Impact of Fairness Constraint   | [paper](https://proceedings.mlr.press/v162/wang22ac/wang22ac.pdf) [code](https://github.com/UCSC-REAL/FairInfl) |   `DA`    | *IF = IF of loss + IF of fairness constraint. It considers several constraints including DP, EOP, covariance, information, etc. and uses NTK to estimate IF.* |
| ICSE'22    | Training data debugging for the fairness of machine learning software | [paper](https://web.archive.org/web/20220717190543id_/https://dl.acm.org/doi/pdf/10.1145/3510003.3510091#page=1.45) [code](https://github.com/fairnesstest/LTDD) |   `DS`    |                                                              |
| ICLR'22    | Domino: Discovering systematic errors with cross-modal embeddings | [paper](https://openreview.net/pdf?id=FPCMqjI0jXN) [code](https://github.com/HazyResearch/domino) | `DA` `DP` |                                                              |
| ICLR'22    | Improving Cooperative Game Theory-based Data Valuation via Data Utility Learning |        [paper](https://arxiv.org/pdf/2107.06336.pdf)         |   `DA`    |                                                              |
| VLDB'22    | Toward Interpretable and Actionable Data Analysis with Explanations and Causality |   [paper](https://www.vldb.org/pvldb/vol15/p3812-roy.pdf)    |   `DP`    |                                                              |
| SIGMOD'22  | Complaint-Driven Training Data Debugging at Interactive Speeds | [paper](https://dl.acm.org/doi/pdf/10.1145/3514221.3517849)  |   `DA`    |                                                              |
| SIGMOD'22  | Interpretable Data-Based Explanations for Fairness Debugging | [paper](https://arxiv.org/pdf/2112.09745.pdf) [video](https://www.youtube.com/watch?v=bt_VL1eSu30) | `DA` `DP` |                                                              |
| ACL'22     | Deduplicating training data makes language models better     | [paper](https://aclanthology.org/2022.acl-long.577.pdf) [code](https://github.com/google-research/deduplicate-text-datasets) |   `DS`    |                                                              |
| AAAI'22    | Scaling Up Influence Functions                               | [paper](https://arxiv.org/pdf/2112.03052.pdf) [code](https://github.com/google-research/jax-influence) |   `DA`    |                                                              |
| AAAI'22    | Incentivizing collaboration in machine learning via synthetic data rewards | [paper](https://ojs.aaai.org/index.php/AAAI/article/view/21177/20926) |   `DA`    |                                                              |
| AISTATS'22 | Beta Shapley: a Unified and Noise-reduced Data Valuation Framework for Machine Learning | [paper](https://proceedings.mlr.press/v151/kwon22a/kwon22a.pdf) [code](https://github.com/ykwon0407/beta_shapley) |   `DA`    |                                                              |

### 2021 and before

| Venue      | Paper                                                        |                            Links                             | Tags | TLDR                                                         |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :--: | :----------------------------------------------------------- |
| NeurIPS'21 | Explaining Latent Representations with a Corpus of Examples  | [paper](https://proceedings.neurips.cc/paper/2021/file/65658fde58ab3c2b6e5132a39fae7cb9-Paper.pdf) [code](https://github.com/JonathanCrabbe/Simplex) | `DA` |                                                              |
| NeurIPS'21 | Validation free and replication robust volume-based data valuation | [paper](https://proceedings.neurips.cc/paper/2021/file/59a3adea76fadcb6dd9e54c96fc155d1-Paper.pdf) [code](https://github.com/ZhaoxuanWu/VolumeBased-DataValuation.) | `DA` |                                                              |
| NeurIPS'21 | Deep Learning on a Data Diet: Finding Important Examples Early in Training |      [paper](https://openreview.net/pdf?id=Uj7pF-D-YvT)      | `DS` |                                                              |
| NeurIPS21  | Interactive Label Cleaning with Example-based Explanations   | [paper](https://proceedings.neurips.cc/paper/2021/file/6c349155b122aa8ad5c877007e05f24f-Paper.pdf) [code](https://github.com/abonte/cincer) | `DP` |                                                              |
| ICML'21    | GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training | [paper](https://proceedings.mlr.press/v139/killamsetty21a/killamsetty21a.pdf) [code](https://github.com/decile-team/cords) | `DS` |                                                              |
| CVPR'21    | Scalability vs. Utility: Do We Have to Sacrifice One for the Other in Data Importance Quantification? | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.pdf) [code](https://github.com/AIsecure/Shapley-Study) | `DA` |                                                              |
| arXiv'21   | A Unified Framework for Task-Driven Data Quality Management  |     [paper](https://arxiv.org/pdf/2106.05484#page=1.37)      | `DA` |                                                              |
| CHI'21     | Data-Centric Explanations: Explaining Training Data of Machine Learning Systems to Promote Transparency |   [paper](https://dl.acm.org/doi/10.1145/3411764.3445736)    | `DP` |                                                              |
| NeurIPS'20 | Multi-Stage Influence Function                               | [paper](https://proceedings.neurips.cc/paper/2020/file/95e62984b87e90645a5cf77037395959-Paper.pdf) | `DA` |                                                              |
| NeurIPS'20 | Estimating Training Data Influence by Tracing Gradient Descent | [paper](https://papers.NeurIPS.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf) [code](https://github.com/frederick0329/TracIn) | `DA` | *TracIn measures the influence of training batched samples during training by estimating the test loss change w.r.t. earlier epochs.* |
| ICML'20    | On second-order group influence functions for black-box predictions | [paper](https://proceedings.mlr.press/v119/basu20b/basu20b.pdf) | `DA` | *The influence score of a group = the sum of individual influence per sample + cross-dependencies among samples in the group.* |
| ICML'20    | Coresets for data-efficient training of machine learning models | [paper](https://proceedings.mlr.press/v119/mirzasoleiman20a/mirzasoleiman20a.pdf) [code](https://github.com/baharanm/craig) | `DS` |                                                              |
| ICML'20    | Optimizing Data Usage via Differentiable Rewards             | [paper](https://proceedings.mlr.press/v119/wang20p/wang20p.pdf) | `DS` |                                                              |
| ICML'20    | Data Valuation using Reinforcement Learning                  | [paper](https://proceedings.mlr.press/v119/yoon20a/yoon20a.pdf) [code](https://github.com/google-research/google-research/tree/master/dvrl) | `DA` | *DVRL employs a learnable NN as data value estimator to select data samples during training and use a RL signal to update it.* |
| ICML'20    | Collaborative Machine Learning with Incentive-Aware Model Rewards | [paper](https://proceedings.mlr.press/v119/sim20a/sim20a.pdf) | `DA` |                                                              |
| ICLR'20    | Selection via proxy: Efficient data selection for deep learning | [paper](https://openreview.net/pdf?id=HJg2b0VYDr) [code](https://github.com/stanford-futuredata/selection-via-proxy) | `DS` |                                                              |
| SIGMOD'20  | Complaint Driven Training Data Debugging for Query'2.0       | [paper](https://arxiv.org/pdf/2004.05722.pdf) [video](https://www.youtube.com/watch?v=qvgBmM1LP38) | `DA` |                                                              |
| PMLR'20    | Identifying Statistical Bias in Dataset Replication          | [paper](https://arxiv.org/abs/2005.09619) [code](https://github.com/MadryLab/dataset-replication-analysis) |      |                                                              |
| NeurIPS'19 | Data Cleansing for Models Trained with SGD                   | [paper](https://proceedings.neurips.cc/paper_files/paper/2019/file/5f14615696649541a025d3d0f8e0447f-Paper.pdf) [code](https://github.com/sato9hara/sgd-influence) | `DA` | *The proposed SGD-Influence scales the influence estimation into SGD-base NNs without the convex and optimal assumptions.* |
| ICML'19    | Data Shapley: Equitable Valuation of Data for Machine Learning | [paper](https://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf) [code](https://github.com/amiratag/DataShapley) | `DA` |                                                              |
| VLDB'19    | Efficient task-specific data valuation for nearest neighbor algorithms |     [paper](https://vldb.org/pvldb/vol12/p1610-jia.pdf)      | `DA` |                                                              |
| AISTATS'19 | Towards Efficient Data Valuation Based on the Shapley Value  | [paper](https://proceedings.mlr.press/v89/jia19a/jia19a.pdf) | `DA` |                                                              |
| ICML'17    | Understanding Black-box Predictions via Influence Functions  | [paper](https://arxiv.org/pdf/1703.04730.pdf) [code](https://github.com/kohpangwei/influence-release) | `DA` |                                                              |

## Surveys

| Venue                          | Paper                                                        |                            Links                             |      Tags      |
| :----------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :------------: |
| arXiv'24                       | Data Quality Awareness: A Journey from Traditional Data Management to Data Science Systems |          [paper](https://arxiv.org/pdf/2411.03007)           |                |
| arXiv'24                       | A Survey on Data Selection for Language Models               |        [paper](https://arxiv.org/pdf/2402.16827.pdf)         |      `DS`      |
| Nature Machine Intelligence'22 | Advances, challenges and opportunities in creating data for trustworthy AI | [paper](https://www.nature.com/articles/s42256-022-00516-1)  |   `DS` `DA`    |
| arXiv'23                       | Data-centric Artificial Intelligence: A Survey               |        [paper](https://arxiv.org/pdf/2303.10158.pdf)         | `DS` `DA` `DP` |
| arXiv'23                       | Data Management For Large Language Models: A Survey          | [paper](https://arxiv.org/pdf/2312.01700.pdf) [code](https://github.com/ZigeW/data_management_LLM) |   `DS` `DA`    |
| arXiv'23                       | Training Data Influence Analysis and Estimation: A Survey    | [paper](https://arxiv.org/pdf/2212.04612.pdf) [code](https://github.com/ZaydH/influence_analysis_papers) |      `DA`      |
| TKDE'22                        | Data Management for Machine Learning: A Survey               |     [paper](https://luoyuyu.vip/files/DM4ML_Survey.pdf)      |   `DS` `DA`    |
| IJCAI'21                       | Data Valuation in Machine Learning: "Ingredients", Strategies, and Open Challenges |   [paper](https://www.ijcai.org/proceedings/2022/0782.pdf)   |      `DA`      |
| TACL'21                        | Explanation-Based Human Debugging of NLP Models: A Survey    |     [paper](https://aclanthology.org/2021.tacl-1.90.pdf)     |   `DP` `DA`    |

## Benchmarks

| Venue      | Paper                                                        |                            Links                             |      Tags      |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :------------: |
| NeurIPS'23 | DataPerf: Benchmarks for Data-Centric AI Development         | [paper](https://openreview.net/pdf?id=LaFKTgrZMG) [code](https://github.com/MLCommons/dataperf) [website](https://dynabench.org/) | `DS` `DA` `DP` |
| NeurIPS'23 | OpenDataVal: a Unified Benchmark for Data Valuation          | [paper](https://openreview.net/pdf?id=eEK99egXeB) [code](https://opendataval.github.io/) |      `DA`      |
| NeurIPS'23 | Improving multimodal datasets with image captioning          | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/45e604a3e33d10fba508e755faa72345-Paper-Datasets_and_Benchmarks.pdf) [code](https://huggingface.co/datasets/thaottn/DataComp_medium_pool_BLIP2_captions) |      `DS`      |
| NeurIPS'23 | Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ae9500c4f5607caf2eff033c67daa9d7-Paper-Datasets_and_Benchmarks.pdf) [code](https://github.com/yueyu1030/AttrPrompt) |      `DS`      |
| DEEM'22    | dcbench: A Benchmark for Data-Centric AI Systems             | [paper](https://dl.acm.org/doi/pdf/10.1145/3533028.3533310?casa_token=hMwaReODUK0AAAAA:ocILXrfHOqC3QkaUltJRHM54vtiBwwBzZhM7QPBYNF5nIgivFRwTqjc3U7TZAvR5wekIuskjHIEwWQ) [code](https://github.com/data-centric-ai/dcbench) |      `DS`      |

## Related Workshops and Tutorials

1. [ICML'23] DMLR Workshop: Data-centric Machine Learning Research [video](https://icml.cc/virtual/2023/workshop/21492) [Website](https://dmlr.ai/)
2. [NeurIPS'23] Tutorial: Data Contribution Estimation for Machine Learning [Website](https://NeurIPS.cc/virtual/2023/tutorial/73959)
3. [ICML'24] Tutorial: Data Attribution at Scale [Website](https://icml.cc/virtual/2024/tutorial/35228)
4. [NeurIPS'24] Tutorial: Advancing Data Selection for Foundation Models: From Heuristics to Principled Methods [Webseite](https://neurips.cc/virtual/2024/tutorial/99530)

## Related Repos

1. More papers about Data Valuation can be found in [awesome-data-valuation](https://github.com/daviddao/awesome-data-valuation). `DA`
2. More papers about Data Pruning can be found in [Awesome-Coreset-Selection](https://github.com/PatrickZH/Awesome-Coreset-Selection). `DS`

## Reference

[1] Gupta, Nitin, et al. "Data quality for machine learning tasks." *Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining*. 2021.

[2] Liang, Weixin, et al. "Advances, challenges and opportunities in creating data for trustworthy AI." *Nature Machine Intelligence* 4.8 (2022): 669-677.