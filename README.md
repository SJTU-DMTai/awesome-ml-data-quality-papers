# Awesome ML Data Quality Papers

This is a list of papers about training data quality management for ML models.

## Introduction

Data scientists spend âˆ¼80% time on data preparation for an ML pipeline since the data quality issues are unknown beforehand thereby leading to iterative debugging [1]. A good Data Quality Management System for ML (**DQMS for ML**) helps data scientists break free from the arduous process of data selection and debugging, particularly in the current era of big data and large models. Automating the management of training data quality effectively is crucial for improving the efficiency and quality of ML pipelines.

With the emergence and development of "**Data-Centric AI**", there has been increasing research focus on optimizing the quality of training data rather than solely concentrating on model structures and training strategies. This is the motivation behind maintaining this repository.

Before we proceed, let's define **data quality for ML**. In contrast to traditional data cleaning, training data quality for ML refers to the impact of individual or groups of data samples on the behavior of ML models for a given task. It's important to note that the behavior of the model we are concerned with goes beyond performance metrics like accuracy, recall, AUC, MSE, etc. We also consider more generalizable metrics such as model fairness, robustness, and so on.

Considering the following pipeline, DQMS acts as a **middleware** between data, ML model, and user, necessitating interactions with each of them.

<div align=center>
<img src="./framework.png" width = "80%" />
</div>


A DQMS for ML typically consists of three components: **Data Sculptor** [2], **Data Attributer**, and **Data Profiler**. To achieve a well-performing ML model, multiple rounds of training are often required. In this process, the DQMS needs to iteratively adjust the training data based on the results of each round of model training. The workflow of DQMS in one round of training is as follows: (a) Data sculptor first acquires the training dataset from a data source and trains the ML model with it. (b) After training for one round (several epochs), Data Attributer absorbs feedback from the model and user's task requirements and computes the data quality assessment. (c) Data Profiler then provides a user-friendly summary of the training data. (d) Meanwhile, Data Sculptor utilizes the data quality assessment as feedback to acquire higher-quality training data, thus initiating a new iteration.

We collect the recent influential papers about DQMS for ML and annotate the relevant DQMS components involved in these papers, where `DS` = Data Sculptor, `DA` = Data Attributer, and `DP` = Data Profiler.

## Paper List

### 2024

| Venue     | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :-------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| ICML'24   | Scaling Laws for the Value of Individual Data Points in Machine Learning |                                                              |   `DA`    |                                                              |
| ICML'24   | Rethinking Data Shapley for Data Selection Tasks: Misleads and Merits |          [paper](https://arxiv.org/pdf/2405.03875)           | `DA` `DS` |                                                              |
| ICML'24   | Distributionally Robust Data Valuation                       |                                                              |   `DA`    |                                                              |
| ICML'24   | Deletion-Anticipative Data Acquisition                       |                                                              |   `DS`    |                                                              |
| ICML'24   | Sensitivity Sampling for Coreset-Based Data Selection        |                                                              |   `DS`    |                                                              |
| ICML'24   | DsDm: Dataset Selection with Datamodels                      |                                                              |   `DS`    |                                                              |
| ICML'24   | BWS: Best Window Selection Based on Sample Scores for Data Pruning across Broad Ranges |                                                              |   `DS`    |                                                              |
| ICML'24   | LESS: Selecting Influential Data for Targeted Instruction Tuning | [paper](https://arxiv.org/pdf/2402.04333v1) [code](https://github.com/princeton-nlp/LESS) |   `DS`    |                                                              |
| arXiv'24  | Training Data Attribution via Approximate Unrolled Differentiation |                                                              |   `DA`    |                                                              |
| VLDB'24   | P-Shapley: Shapley Values on Probabilistic Classifiers       | [paper](https://www.vldb.org/pvldb/vol17/p1737-liu.pdf) [code](https://github.com/ZJU-DIVER/P-Shapley) |   `DA`    | *This paper introduces P-Shapley with raw probability (instead of accuracy) as utility function and proposes calibration function to enlarge the utility change when the predicted probability is high.* |
| VLDB'24   | MetaStore: Analyzing Deep Learning Meta-Data at Scale        |   [paper](https://www.vldb.org/pvldb/vol17/p1446-cao.pdf)    | `DA` `DP` |                                                              |
| VLDB'24   | Optimizing Data Acquisition to Enhance Machine Learning Performance | [paper](https://www.vldb.org/pvldb/vol17/p1310-bao.pdf) [code](https://github.com/rmitbggroup/da-ml) |   `DS`    |                                                              |
| VLDB'24   | MisDetect: Iterative Mislabel Detection using Early Loss     | [paper](https://www.vldb.org/pvldb/vol17/p1159-chai.pdf) [code](https://github.com/anonymous-repo1/misdetect) |   `DA`    |                                                              |
| SIGMOD'24 | Data Acquisition for Improving Model Confidence              |                                                              |           |                                                              |
| SIGMOD'24 | Controllable Tabular Data Synthesis Using Diffusion Models   |                                                              |   `DS`    |                                                              |
| SIGMOD'24 | Fast Shapley Value Computation in Data Assemblage Tasks as Cooperative Simple Games | [paper](https://xuc.me/file/paper/SIGMOD24b.pdf) [code](https://github.com/IDEAL-Lab/shapley-value-simple-game) |   `DA`    | *It assigns a Shapley score for data owners and their corresponding datasets in data market.* |
| WWW'24    | Exploring Neural Scaling Law and Data Pruning Methods For Node Classification on Large-scale Graphs | [paper](https://dl.acm.org/doi/pdf/10.1145/3589334.3645571) [code](https://github.com/joneswong/GNSL) |   `DS`    | *This work selects training nodes that are similar to test nodes by minimizing their bottleneck distance. To avoid bias caused by trivial selection, it uses a greedy alg. to assure the representativeness of selected nodes.* |
| AAAI'24   | Quality-Diversity Generative Sampling for Learning with Synthetic Data | [paper](https://ojs.aaai.org/index.php/AAAI/article/download/29955/31670) [code](https://github.com/Cylumn/qd-generative-sampling) |   `DS`    |                                                              |
| AAAI'24   | Approximating the Shapley Value without Marginal Contributions | [paper](https://ojs.aaai.org/index.php/AAAI/article/download/29225/30311) |   `DA`    |                                                              |
| WSDM'24   | FairIF: Boosting Fairness in Deep Learning via Influence Functions with Validation Set Sensitive Attributes | [paper](https://dl.acm.org/doi/pdf/10.1145/3616855.3635844?casa_token=0-2Cnoe2_kQAAAAA:kOtBF3rsnlzcX0tv-6og4n5LFG-xBbphXH_Aga45OeQUyJUpQBh4Bkoydcu2gf_8rFej0ljKUBFz) |   `DA`    |                                                              |
| WSDM'24   | Efficient, Direct, and Restricted Black-Box Graph Evasion Attacks to Any-Layer Graph Neural Networks via Influence Function | [paper](https://dl.acm.org/doi/pdf/10.1145/3616855.3635826?casa_token=p1rDbOded6oAAAAA:-8uNJw5R4pGO-f4J02uKQZdOsOfEITqeF6nh6dh9tcriDDItmSzlZahoeB9Q6na07Eywpnq7oNR1) [code](https://github.com/ventr1c/InfAttack) |   `DA`    |                                                              |
| ICLR'24   | "What Data Benefits My Classifier?" Enhancing Model Performance and Interpretability through Influence-Based Data Selection | [paper](https://openreview.net/pdf?id=HE9eUQlAvo) [code](https://github.com/anshuman23/InfDataSel) | `DS` `DA` | *It extends influence function considering utility, fairness and robustness. It trains a decision tree to further estimate and interpret the influence score.* |
| ICLR'24   | Canonpipe: Data Debugging with Shapley Importance over Machine Learning Pipelines | [paper](https://xuc.me/file/paper/SIGMOD24b.pdf) [code](https://github.com/IDEAL-Lab/shapley-value-simple-game) |   `DA`    | *It explores data valuation on raw data before preprocessing. It uses data provenance in ML pipelines and proposes data Shapley under a KNN approximation.* |
| ICLR'24   | Time Travel in LLMs: Tracing Data Contamination in Large Language Models | [paper](https://openreview.net/pdf?id=2Rwq6c3tvr) [code](https://github.com/shahriargolchin/time-travel-in-llms) |   `DA`    | *Data contamination means the presence of test data from downstream tasks in the pre-training data of LLMs. This work explore both instance and partition level methods to identify potential contamination.* |
| ICLR'24   | GIO: Gradient Information Optimization for Training Dataset Selection | [paper](https://openreview.net/pdf?id=3NnfJnbJT2) [code](https://github.com/daeveraert/gradient-information-optimization) |   `DA`    | *GIO selects a small subset of data from large source data by minimizing the KL divergence between the target distribution and subset.* |
| ICLR'24   | Intriguing Properties of Data Attribution on Diffusion Models | [paper](https://openreview.net/pdf?id=vKViCoKGcB) [code](https://github.com/sail-sg/D-TRAK) |   `DA`    | *This paper proposes D-TRAK to attribute images generated by diffusion models back to the training data.* |
| ICLR'24   | D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning | [paper](https://openreview.net/pdf?id=thbtoAkCe9) [code](https://github.com/adymaharana/d2pruning) |   `DS`    | *A data pruning method that takes diversity into consideration. It is implemented by forward and reverse message passing in the KNN graph.* |
| ICLR'24   | Effective pruning of web-scale datasets based on complexity of concept clusters | [paper](https://openreview.net/pdf?id=CtOA9aN8fr) [code](https://github.com/amro-kamal/effective_pruning) |   `DS`    |                                                              |
| ICLR'24   | Towards a statistical theory of data selection under weak supervision |      [paper](https://openreview.net/pdf?id=HhfcNgQn6p)       |   `DS`    |                                                              |
| ICLR'24   | Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs | [paper](https://openreview.net/pdf?id=QmYNBVukex) [code](https://anonymous.4open.science/r/DV4LLM-D761/) |   `DS`    |                                                              |
| ICLR'24   | DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models | [paper](https://openreview.net/pdf?id=9m02ib92Wz) [code](https://github.com/ykwon0407/DataInf) |   `DA`    | *DataInf approximate influence function by swapping the order of the matrix inversion and average calculation.* |
| ICLR'24   | What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning |      [paper](https://openreview.net/pdf?id=BTKAeLqLMw)       |   `DS`    |                                                              |
| ICLR'24   | Real-Fake: Effective Training Data Synthesis Through Distribution Matching | [paper](http://arxiv.org/pdf/2310.10402.pdf) [code](http://arxiv.org/pdf/2310.10402.pdf) |   `DS`    |                                                              |
| ICLR'24   | InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning | [paper](https://openreview.net/pdf?id=C61sk5LsK6) [code](https://github.com/NUS-HPC-AI-Lab/InfoBatch) |   `DS`    | *InfoBatch uses training loss to prune well-learned samples in each epoch and estimate gradient distribution for unbiased learning.* |
| arXiv'24  | A Decade's Battle on Dataset Bias: Are We There Yet?         | [paper](https://arxiv.org/pdf/2403.08632.pdf) [code](http://github.com/liuzhuang13/bias) |   `DS`    |                                                              |
| arXiv'24  | Chameleon: Foundation Models for Fairness-aware Multi-modal Data Augmentation to Enhance Coverage of Minorities | [paper](https://arxiv.org/pdf/2402.01071.pdf) [code](https://github.com/UIC-InDeXLab/Chameleon) |   `DS`    | *It uses generative AI for augmentation, ensuring that the generated data covering the original data distribution with a smallest size.* |
| arXiv'24  | On the Cause of Unfairness: A Training Sample Perspective    |       [paper](https://arxiv.org/pdf/2306.17828v2.pdf)        |   `DA`    | *The fairness influence can be computed by replacing the training sample with its concept counterfactual sample.* |

### 2023

| Venue            | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :--------------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| arXiv'23         | The Journey, Not the Destination: How Data Guides Diffusion Models | [paper](http://arxiv.org/pdf/2312.06205.pdf) [code](https://github.com/MadryLab/journey-TRAK) |   `DA`    | -                                                            |
| NIPS'23          | The Memory Perturbation Equation: Understanding Modelâ€™s Sensitivity to Data | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/550ab405d0addd3de5b70e57b44878df-Paper-Conference.pdf) [code](https://github.com/team-approx-bayes/memory-perturbation) |   `DA`    | -                                                            |
| NIPS'23          | Theoretical and Practical Perspectives on what Influence Functions Do |      [paper](https://openreview.net/pdf?id=gGl0n7Onug)       |   `DA`    | This work discusses some problematic assumptions of IF. While most of them can be addressed, IF can predict perturbated param accurately for a limited amount of time-steps. |
| NIPS'23          | Data Selection for Language Models via Importance Resampling | [paper](https://openreview.net/pdf?id=uPSQv0leAu) [code](https://github.com/p-lambda/dsir) | `DS` `DA` | *It selects data satisfying a target distribution from raw data by reducing KL divergence to the target over random selection.* |
| NIPS'23          | Model Shapley: Equitable Model Valuation with Black-box Access | [paper](https://openreview.net/pdf?id=Y6IGTNMdLT) [code](https://github.com/XinyiYS/ModelShapley) |   `DA`    | -                                                            |
| NIPS'23          | Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation |      [paper](https://openreview.net/pdf?id=FAZ3i0hvm0)       |   `DA`    | *Extend KNN-Shapley while considering data privacy.*         |
| NIPS'23          | GEX: A flexible method for approximating influence via Geometric Ensemble | [paper](https://openreview.net/attachment?id=tz4ECtAu8e&name=pdf) [code](https://github.com/sungyubkim/gex) |   `DA`    | -                                                            |
| NIPS'23          | Efficient Data Subset Selection to Generalize Training Across Models: Transductive and Inductive Networks | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/0f25eb6e9dc26c933a5d7516abf1eb8c-Paper-Conference.pdf) [code](https://github.com/structlearning/subselnet) |   `DS`    | -                                                            |
| NIPS'23          | Data Pruning via Moving-one-Sample-out                       | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/3abe23bf7e295b44369c24465d68987a-Paper-Conference.pdf) |   `DS`    | *This work proposes a Moso score (similar to LOO) and an approximates it using gradient over all training epochs.* |
| NIPS'23          | Towards Free Data Selection with General-Purpose Models      | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/047682108c3b053c61ad2da5a6057b4e-Paper-Conference.pdf) [code](https://github.com/yichen928/FreeSel) |   `DS`    | -                                                            |
| NIPS'23          | Towards Accelerated Model Training via Bayesian Data Selection | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/1af3e0bf5905e33789979f666c31192d-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NIPS'23          | Robust Data Valuation with Weighted Banzhaf Values           | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/bdb0596d13cfccf2db6f0cc5280d2a3f-Paper-Conference.pdf) |   `DA`    | -                                                            |
| NIPS'23          | UP-DP: Unsupervised Prompt Learning for Data Pre-Selection with Vision-Language Models | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/06d5f1fe6509b001e6d4e0ec1afd83dd-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NIPS'23          | Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/c142c14699223f7417cad706fd6f652e-Paper-Conference.pdf) [code](https://github.com/ruoxi-jia-group/projektor) |   `DS`    | *Given publicly known pilot data from different data sources, it returns the optimal combination of data sources.* |
| NIPS'23          | Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ebb6bee50913ba7e1efeb91a1d47a002-Paper-Conference.pdf) [code](https://github.com/kaist-dmlab/Prune4Rel) |   `DS`    | -                                                            |
| NIPS'23          | Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/81cca94f16f20d5548c76c3344b27dea-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NIPS'23          | Core-sets for Fair and Diverse Data Summarization            | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/f980ba94f513168f2b292f58aef929ec-Paper-Conference.pdf) [code](https://github.com/microsoft/coresets-fair-diverse) | `DS` `DP` | -                                                            |
| NIPS'23          | Retaining Beneficial Information from Detrimental Data for Neural Network Repair | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/964b1c8dd5667fd647c09c8772829fd1-Paper-Conference.pdf) |   `DS`    | -                                                            |
| NIPS'23          | Expanding Small-Scale Datasets with Guided Imagination       | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/f188a55392d3a7509b0b27f8d24364bb-Paper-Conference.pdf) [code](https://github.com/Vanint/DatasetExpansion) |   `DS`    | -                                                            |
| NIPS'23          | Error Discovery By Clustering Influence Embeddings           | [paper](https://openreview.net/pdf?id=yBVLXvJ1sb) [code](https://github.com/adebayoj/infembed) |   `DA`    | -                                                            |
| NIPS'23          | HiBug: On Human-Interpretable Model Debug                    | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/0f53ecc0d36a5d5d3d3e94d42c4b23ca-Paper-Conference.pdf) [code](https://github.com/cure-lab/HiBug) | `DP` `DS` | -                                                            |
| NIPS'23          | Skill-it! A data-driven skills framework for understanding and training language models | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/70b8505ac79e3e131756f793cd80eb8d-Paper-Conference.pdf) [code](https://github.com/HazyResearch/skill-it) | `DP` `DS` | -                                                            |
| ICML'23          | Discover and Cure: Concept-aware Mitigation of Spurious Correlation | [paper](https://openreview.net/pdf?id=QDxtrlPmfB) [code](https://github.com/Wuyxin/DISC) | `DS` `DA` | *Discover spurious correlation from concept level and perform concept-based data augmentation to mitigate bias.* |
| ICML'23          | TRAK: Attributing Model Behavior at Scale                    | [paper](https://openreview.net/pdf?id=PBRArApxMh) [code](https://github.com/MadryLab/trak) |   `DA`    | *TRAK first defines a Newton approximation to estimate LOO for logistic regression and then extends it to NNs (including CLIP, mT5) by view them as the linear model acting on input gradient.* |
| ICML'23          | RGE: A Repulsive Graph Rectification for Node Classification via Influence | [paper](https://proceedings.mlr.press/v202/song23f/song23f.pdf) [code](https://github.com/Jaeyun-Song/RGE.git) |   `DA`    | *RGE identifies a group of negative edges that are most harmful for GNNs. It iteratively selects negative edges by their individual influence and prefers distant edges first.* |
| ICML'23          | Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value | [paper](https://proceedings.mlr.press/v202/kwon23e/kwon23e.pdf) [code](https://github.com/ykwon0407/dataoob) |   `DA`    | *Data-OOB measures the average score when a datum (OOB data) is not selected in the bootstrap dataset.* |
| ICML'23          | Towards Sustainable Learning: Coresets for Data-efficient Deep Learning | [paper](https://proceedings.mlr.press/v202/yang23g/yang23g.pdf) [code](https://github.com/bigml-cs-ucla/crest) |   `DS`    | -                                                            |
| ICML'23 Workshop | Training on Thin Air: Improve Image Classification with Generated Data | [paper](https://dmlr.ai/assets/accepted-papers/9/CameraReady/Diffusion_Inversion_DMLR_ICML2023_compressed.pdf) |   `DS`    | -                                                            |
| ICML'23 Workshop | Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation | [paper](https://dmlr.ai/assets/accepted-papers/49/CameraReady/icml.pdf) [code](https://github.com/MadryLab/dataset-interfaces) | `DA` `DS` | -                                                            |
| VLDB'23          | Equitable Data Valuation Meets the Right to Be Forgotten in Model Markets | [paper](https://www.vldb.org/pvldb/vol16/p3349-liu.pdf) [code](https://github.com/ZJU-DIVER/ValuationMeetsRTBF) |   `DA`    | -                                                            |
| VLDB'23          | Computing Rule-Based Explanations by Leveraging Counterfactuals | [paper](https://www.vldb.org/pvldb/vol16/p420-geng.pdf) [code](https://github.com/GibbsG/GeneticCF) |   `DP`    | -                                                            |
| VLDB'23          | Data Collection and Quality Challenges for Deep Learning     |  [paper](https://www.vldb.org/pvldb/vol13/p3429-whang.pdf)   | `DS` `DA` | -                                                            |
| SIGMOD'23        | GoodCore: Coreset Selection over Incomplete Data for Data-effective and Data-efficient Machine Learning |     [paper](https://dl.acm.org/doi/pdf/10.1145/3589302)      |   `DS`    | *GoodCore selects a coreset that achieves expected low gradient approximation error among all possible worlds of missing data.* |
| SIGMOD'23        | XInsight: eXplainable Data Analysis Through The Lens of Causality |        [paper](https://arxiv.org/pdf/2207.12718.pdf)         |   `DP`    | -                                                            |
| SIGMOD'23        | HybridPipe: Combining Human-generated and Machine-generated Pipelines for Data Preparation | [paper](https://dbgroup.cs.tsinghua.edu.cn/ligl/papers/haipipe-acm.pdf) [code](https://github.com/ruc-datalab/Haipipe) | `DS` `DP` | -                                                            |
| arXiv'23         | Simfluence: Modeling the influence of individual training examples by simulating training runs |          [paper](https://arxiv.org/pdf/2303.08114)           |   `DS`    |                                                              |
| ICLR'23          | Data Valuation Without Training of a Model                   | [paper](https://openreview.net/pdf?id=XIzO8zr-WbM) [code](https://github.com/JJchy/CG_score) |   `DA`    | *It proposes a score to measures the gap in data complexity where a certain data instance is removed from the full dataset.* |
| ICLR'23          | Distilling Model Failures as Directions in Latent Space      | [paper](https://openreview.net/pdf?id=99RpBVpLiX) [code](https://github.com/MadryLab/failure-directions) | `DS` `DP` | -                                                            |
| ICLR'23          | LAVA: Data Valuation without Pre-Specified Learning Algorithms | [paper](https://openreview.net/pdf?id=JJuP86nBl4q) [code](https://github.com/ruoxi-jia-group/LAVA) |   `DA`    | *LAVA uses a Wasserstein distance to estimate the upper bound of test performance. It values a training sample by its sensitivity to the distance.* |
| ICLR'23          | Concept-level Debugging of Part-Prototype Networks           | [paper](https://openreview.net/pdf?id=oiwXWPDTyNk) [code](https://github.com/abonte/protopdebug) |   `DP`    | -                                                            |
| ICLR'23          | Dataset Pruning: Reducing Training Data by Examining Generalization Influence |      [paper](https://openreview.net/pdf?id=4wZiAXD29TQ)      |   `DS`    | -                                                            |
| ICLR'23          | Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning | [paper](https://openreview.net/pdf?id=7D5EECbOaf9) [code](https://github.com/tmllab/Moderate-`DS`) |   `DS`    | -                                                            |
| ICLR'23          | Learning to Estimate Shapley Values with Vision Transformers | [paper](https://openreview.net/pdf?id=5ktFNz_pJLK) [code](https://github.com/suinleelab/vit-shapley) |   `DA`    | -                                                            |
| ICLR'23          | Characterizing the Influence of Graph Elements               | [paper](https://openreview.net/pdf?id=51GXyzOKOp) [code](https://github.com/Cyrus9721/Characterizing_graph_influence) |   `DA`    | *Introduce influence function into graphs, considering node- and edge-removal influence and the linear SGC model.* |
| ICDE'23          | Automatic Feasibility Study via Data Quality Analysis for ML: A Case-Study on Label Noise | [paper](https://arxiv.org/pdf/2010.08410.pdf) [code](https://github.com/easeml/snoopy) |   `DP`    | -                                                            |
| ICDE'23          | Detection of Groups with Biased Representation in Ranking    |        [paper](https://arxiv.org/pdf/2301.00719.pdf)         |   `DA`    | -                                                            |
| AAAI'23          | Fundamentals of Task-Agnostic Data Valuation                 | [paper](https://ojs.aaai.org/index.php/AAAI/article/view/26106/25878) |   `DA`    | -                                                            |
| AAAI'23          | Interpreting Unfairness in Graph Neural Networks via Training Node Attribution | [paper](https://ojs.aaai.org/index.php/AAAI/article/view/25905/25677) [code](https://github.com/yushundong/BIND) |   `DA`    | *This work proposes a Probabilistic Distribution Disparity to define node-contributed model bias and use gradient approximation to estimate node-level bias.* |
| AAAI'23          | Interpreting Unfairness in Graph Neural Networks via Training Node Attribution | [paper](https://ojs.aaai.org/index.php/AAAI/article/download/25905/25677) [code](https://github.com/yushundong/BIND) |   `DA`    |                                                              |
| WWW'23           | GIF: A General Graph Unlearning Strategy via Influence Function | [paper](https://arxiv.org/pdf/2304.02835.pdf) [code](https://github.com/wujcan/GIF-torch/) |   `DA`    | *GIF extends influence function to graph data by considering both the directly affected node(s) and the influenced neighborhoods.* |
| AISTATS'23       | Data Banzhaf: A Robust Data Valuation Framework for Machine Learning | [paper](https://proceedings.mlr.press/v206/wang23e/wang23e.pdf) |   `DA`    | -                                                            |
| arXiv'23         | Data-Juicer: A One-Stop Data Processing System for Large Language Models | [paper](https://arxiv.org/pdf/2309.02033.pdf) [code](https://github.com/alibaba/data-juicer) | `DS` `DP` | -                                                            |
| arXiv'23         | Simï¬‚uence: Modeling the inï¬‚uence of individual training examples by simulating training runs |          [paper](https://arxiv.org/pdf/2303.08114)           |   `DA`    |                                                              |
| arXiv'23         | Studying Large Language Model Generalization with Influence Functions |        [paper](https://arxiv.org/pdf/2308.03296.pdf)         |   `DA`    | -                                                            |
| TMLR'23          | Synthetic Data from Diffusion Models Improves ImageNet Classification |        [paper](https://arxiv.org/pdf/2304.08466.pdf)         |   `DS`    | -                                                            |

### 2022

| Venue      | Paper                                                        |                            Links                             |   Tags    | TLDR                                                         |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :-------: | :----------------------------------------------------------- |
| NIPS'22    | CS-SHAPLEY: Class-wise Shapley Values for Data Valuation in Classification | [paper](https://openreview.net/pdf?id=KTOcrOR5mQ9) [code](https://github.com/stephanieschoch/cs-shapley) |   `DA`    |                                                              |
| NIPS'22    | Beyond neural scaling laws: beating power law scaling via data pruning |      [paper](https://openreview.net/pdf?id=UmvSlP-PyV)       |   `DS`    |                                                              |
| NIPS'22    | Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP | [paper](https://openreview.net/pdf?id=LTCBavFWp5C) [code](https://github.com/mlfoundations/clip_quality_not_quantity) |   `DS`    |                                                              |
| NIPS'22    | Quantifying memorization across neural language models       | [paper](https://arxiv.org/pdf/2202.07646.pdf?trk=public_post_comment-text) |   `DA`    |                                                              |
| ICML'22    | Measuring the Effect of Training Data on Deep Learning Predictions via Randomized Experiments | [paper](https://proceedings.mlr.press/v162/lin22h/lin22h.pdf) |   `DA`    | *It proposes the AME score $E_S[U(S\cup {z})-U(S)]$ with $S$ being a random set. The AME score can be approximated by a LASSO model.* |
| ICML'22    | Meaningfully Debugging Model Mistakes using Conceptual Counterfactual Explanations | [papeer](https://proceedings.mlr.press/v162/abid22a/abid22a.pdf) [code](https://github.com/mertyg/debug-mistakes-cce) | `DS` `DP` | *It learns CAV and move those misclassified training samples toward the direction of CAV.* |
| ICML'22    | Datamodels: Predicting Predictions from Training Data        | [paper](https://proceedings.mlr.press/v162/ilyas22a/ilyas22a.pdf) [code](https://github.com/MadryLab/datamodels-data) |   `DA`    | *Datamodels learns a linear model to predict the model output on one test data. It takes as input the one-hot mask of training samples.* |
| ICML'22    | Prioritized Training on Points that are learnable, Worth Learning, and Not Yet Learnt | [paper](https://proceedings.mlr.press/v162/mindermann22a/mindermann22a.pdf) [code](https://github.com/OATML/RHO-Loss) |   `DS`    |                                                              |
| ICML'22    | Achieving Fairness at No Utility Cost via Data Reweighing with Influence | [paper](https://proceedings.mlr.press/v162/li22p/li22p.pdf) [code](https://github.com/brandeis-machine-learning/influence-fairness) |   `DA`    | *It employs DP and EOP to compute IF and performs soft reweighing on training samples. The proof of no-utility-degradation is provided.* |
| ICML'22    | DAVINZ: Data Valuation using Deep Neural Networks at Initialization | [paper](https://proceedings.mlr.press/v162/wu22j/wu22j.pdf)  |   `DA`    | *It uses NTK-based bound to approximate validation performance without training.* |
| ICML'22    | Understanding Instance-Level Impact of Fairness Constraint   | [paper](https://proceedings.mlr.press/v162/wang22ac/wang22ac.pdf) [code](https://github.com/UCSC-REAL/FairInfl) |   `DA`    | *IF = IF of loss + IF of fairness constraint. It considers several constraints including DP, EOP, covariance, information, etc. and uses NTK to estimate IF.* |
| ICLR'22    | Domino: Discovering systematic errors with cross-modal embeddings | [paper](https://openreview.net/pdf?id=FPCMqjI0jXN) [code](https://github.com/HazyResearch/domino) | `DA` `DP` |                                                              |
| ICLR'22    | Improving Cooperative Game Theory-based Data Valuation via Data Utility Learning |        [paper](https://arxiv.org/pdf/2107.06336.pdf)         |   `DA`    |                                                              |
| VLDB'22    | Toward Interpretable and Actionable Data Analysis with Explanations and Causality |   [paper](https://www.vldb.org/pvldb/vol15/p3812-roy.pdf)    |   `DP`    |                                                              |
| SIGMOD'22  | Complaint-Driven Training Data Debugging at Interactive Speeds | [paper](https://dl.acm.org/doi/pdf/10.1145/3514221.3517849)  |   `DA`    |                                                              |
| SIGMOD'22  | Interpretable Data-Based Explanations for Fairness Debugging | [paper](https://arxiv.org/pdf/2112.09745.pdf) [video](https://www.youtube.com/watch?v=bt_VL1eSu30) | `DA` `DP` |                                                              |
| ACL'22     | Deduplicating training data makes language models better     | [paper](https://aclanthology.org/2022.acl-long.577.pdf) [code](https://github.com/google-research/deduplicate-text-datasets) |   `DS`    |                                                              |
| AAAI'22    | Scaling Up Influence Functions                               | [paper](https://arxiv.org/pdf/2112.03052.pdf) [code](https://github.com/google-research/jax-influence) |   `DA`    |                                                              |
| AISTATS'22 | Beta Shapley: a Unified and Noise-reduced Data Valuation Framework for Machine Learning | [paper](https://proceedings.mlr.press/v151/kwon22a/kwon22a.pdf) [code](https://github.com/ykwon0407/beta_shapley) |   `DA`    |                                                              |

### 2021 and before

| Venue     | Paper                                                        |                            Links                             | Tags | TLDR                                                         |
| :-------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :--: | :----------------------------------------------------------- |
| NIPS'21   | Explaining Latent Representations with a Corpus of Examples  | [paper](https://proceedings.neurips.cc/paper/2021/file/65658fde58ab3c2b6e5132a39fae7cb9-Paper.pdf) [code](https://github.com/JonathanCrabbe/Simplex) | `DA` |                                                              |
| NIPS'21   | Validation free and replication robust volume-based data valuation | [paper](https://proceedings.neurips.cc/paper/2021/file/59a3adea76fadcb6dd9e54c96fc155d1-Paper.pdf) [code](https://github.com/ZhaoxuanWu/VolumeBased-DataValuation.) | `DA` |                                                              |
| NIPS'21   | Deep Learning on a Data Diet: Finding Important Examples Early in Training |      [paper](https://openreview.net/pdf?id=Uj7pF-D-YvT)      | `DS` |                                                              |
| NIPS21    | Interactive Label Cleaning with Example-based Explanations   | [paper](https://proceedings.neurips.cc/paper/2021/file/6c349155b122aa8ad5c877007e05f24f-Paper.pdf) [code](https://github.com/abonte/cincer) | `DP` |                                                              |
| ICML'21   | GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training | [paper](https://proceedings.mlr.press/v139/killamsetty21a/killamsetty21a.pdf) [code](https://github.com/decile-team/cords) | `DS` |                                                              |
| CVPR'21   | Scalability vs. Utility: Do We Have to Sacrifice One for the Other in Data Importance Quantification? | [paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.pdf) [code](https://github.com/AIsecure/Shapley-Study) | `DA` |                                                              |
| CHI'21    | Data-Centric Explanations: Explaining Training Data of Machine Learning Systems to Promote Transparency |   [paper](https://dl.acm.org/doi/10.1145/3411764.3445736)    | `DP` |                                                              |
| NIPS'20   | Multi-Stage Influence Function                               | [paper](https://proceedings.neurips.cc/paper/2020/file/95e62984b87e90645a5cf77037395959-Paper.pdf) | `DA` |                                                              |
| NIPS'20   | Estimating Training Data Influence by Tracing Gradient Descent | [paper](https://papers.nips.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf) [code](https://github.com/frederick0329/TracIn) | `DA` | *TracIn measures the influence of training batched samples during training by estimating the test loss change w.r.t. earlier epochs.* |
| ICML'20   | On second-order group influence functions for black-box predictions | [paper](https://proceedings.mlr.press/v119/basu20b/basu20b.pdf) | `DA` | *The influence score of a group = the sum of individual influence per sample + cross-dependencies among samples in the group.* |
| ICML'20   | Coresets for data-efficient training of machine learning models | [paper](https://proceedings.mlr.press/v119/mirzasoleiman20a/mirzasoleiman20a.pdf) [code](https://github.com/baharanm/craig) | `DS` |                                                              |
| ICML'20   | Optimizing Data Usage via Differentiable Rewards             | [paper](https://proceedings.mlr.press/v119/wang20p/wang20p.pdf) | `DS` |                                                              |
| ICML'20   | Data Valuation using Reinforcement Learning                  | [paper](https://proceedings.mlr.press/v119/yoon20a/yoon20a.pdf) [code](https://github.com/google-research/google-research/tree/master/dvrl) | `DA` | *DVRL employs a learnable NN as data value estimator to select data samples during training and use a RL signal to update it.* |
| ICLR'20   | Selection via proxy: Efficient data selection for deep learning | [paper](https://openreview.net/pdf?id=HJg2b0VYDr) [code](https://github.com/stanford-futuredata/selection-via-proxy) | `DS` |                                                              |
| SIGMOD'20 | Complaint Driven Training Data Debugging for Query'2.0       | [paper](https://arxiv.org/pdf/2004.05722.pdf) [video](https://www.youtube.com/watch?v=qvgBmM1LP38) | `DA` |                                                              |
| PMLR'20   | Identifying Statistical Bias in Dataset Replication          | [paper](https://arxiv.org/abs/2005.09619) [code](https://github.com/MadryLab/dataset-replication-analysis) |      |                                                              |
| NIPS'19   | Data Cleansing for Models Trained with SGD                   | [paper](https://proceedings.neurips.cc/paper_files/paper/2019/file/5f14615696649541a025d3d0f8e0447f-Paper.pdf) [code](https://github.com/sato9hara/sgd-influence) | `DA` | *The proposed SGD-Influence scales the influence estimation into SGD-base NNs without the convex and optimal assumptions.* |
| ICML'19   | Data Shapley: Equitable Valuation of Data for Machine Learning | [paper](https://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf) [code](https://github.com/amiratag/DataShapley) | `DA` |                                                              |
| VLDB'19   | Efficient task-specific data valuation for nearest neighbor algorithms |     [paper](https://vldb.org/pvldb/vol12/p1610-jia.pdf)      | `DA` |                                                              |
| ICML'17   | Understanding Black-box Predictions via Influence Functions  | [paper](https://arxiv.org/pdf/1703.04730.pdf) [code](https://github.com/kohpangwei/influence-release) | `DA` |                                                              |

## Surveys

| Venue                          | Paper                                                        |                            Links                             |      Tags      |
| :----------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: | :------------: |
| arXiv'24                       | A Survey on Data Selection for Language Models               |        [paper](https://arxiv.org/pdf/2402.16827.pdf)         |      `DS`      |
| Nature Machine Intelligence'22 | Advances, challenges and opportunities in creating data for trustworthy AI | [paper](https://www.nature.com/articles/s42256-022-00516-1)  |   `DS` `DA`    |
| arXiv'23                       | Data-centric Artificial Intelligence: A Survey               |        [paper](https://arxiv.org/pdf/2303.10158.pdf)         | `DS` `DA` `DP` |
| arXiv'23                       | Data Management For Large Language Models: A Survey          | [paper](https://arxiv.org/pdf/2312.01700.pdf) [code](https://github.com/ZigeW/data_management_LLM) |   `DS` `DA`    |
| arXiv'23                       | Training Data Influence Analysis and Estimation: A Survey    | [paper](https://arxiv.org/pdf/2212.04612.pdf) [code](https://github.com/ZaydH/influence_analysis_papers) |      `DA`      |
| TKDE'22                        | Data Management for Machine Learning: A Survey               |     [paper](https://luoyuyu.vip/files/DM4ML_Survey.pdf)      |   `DS` `DA`    |
| IJCAI'21                       | Data Valuation in Machine Learning: "Ingredients", Strategies, and Open Challenges |   [paper](https://www.ijcai.org/proceedings/2022/0782.pdf)   |      `DA`      |
| TACL'21                        | Explanation-Based Human Debugging of NLP Models: A Survey    |     [paper](https://aclanthology.org/2021.tacl-1.90.pdf)     |   `DP` `DA`    |

## Benchmarks

| Venue   | Paper                                                        |                            Links                             |      Tags      |
| :------ | :----------------------------------------------------------- | :----------------------------------------------------------: | :------------: |
| NIPS'23 | DataPerf: Benchmarks for Data-Centric AI Development         | [paper](https://openreview.net/pdf?id=LaFKTgrZMG) [code](https://github.com/MLCommons/dataperf) [website](https://dynabench.org/) | `DS` `DA` `DP` |
| NIPS'23 | OpenDataVal: a Unified Benchmark for Data Valuation          | [paper](https://openreview.net/pdf?id=eEK99egXeB) [code](https://opendataval.github.io/) |      `DA`      |
| NIPS'23 | Improving multimodal datasets with image captioning          | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/45e604a3e33d10fba508e755faa72345-Paper-Datasets_and_Benchmarks.pdf) [code](https://huggingface.co/datasets/thaottn/DataComp_medium_pool_BLIP2_captions) |      `DS`      |
| NIPS'23 | Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias | [paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ae9500c4f5607caf2eff033c67daa9d7-Paper-Datasets_and_Benchmarks.pdf) [code](https://github.com/yueyu1030/AttrPrompt) |      `DS`      |
| DEEM'22 | dcbench: A Benchmark for Data-Centric AI Systems             | [paper](https://dl.acm.org/doi/pdf/10.1145/3533028.3533310?casa_token=hMwaReODUK0AAAAA:ocILXrfHOqC3QkaUltJRHM54vtiBwwBzZhM7QPBYNF5nIgivFRwTqjc3U7TZAvR5wekIuskjHIEwWQ) [code](https://github.com/data-centric-ai/dcbench) |      `DS`      |

## Related Workshops

1. [ICML'23] DMLR Workshop: Data-centric Machine Learning Research [video](https://icml.cc/virtual/2023/workshop/21492) [DMLR Website](https://dmlr.ai/)

## Related Repos

1. More papers about Data Valuation can be found in [awesome-data-valuation](https://github.com/daviddao/awesome-data-valuation). `DA`
2. More papers about Data Pruning can be found in [Awesome-Coreset-Selection](https://github.com/PatrickZH/Awesome-Coreset-Selection). `DS`

## Reference

[1] Gupta, Nitin, et al. "Data quality for machine learning tasks." *Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining*. 2021.

[2] Liang, Weixin, et al. "Advances, challenges and opportunities in creating data for trustworthy AI." *Nature Machine Intelligence* 4.8 (2022): 669-677.